[{"authors":["admin"],"categories":null,"content":" I’m a software engineer at RStudio. Most of my work involves creating R packages that make it easier to work with and communicate data. I also enjoy opportunities to teach people how to be successful with R.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"d33c1cd8bead9ce2a6229ddb7fdca4a5","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I’m a software engineer at RStudio. Most of my work involves creating R packages that make it easier to work with and communicate data. I also enjoy opportunities to teach people how to be successful with R.","tags":null,"title":"Richard Iannone","type":"authors"},{"authors":[],"categories":[],"content":"    English  French  German    The newest release of the pointblank package makes it really easy to validate your data with workflows attuned to your data quality needs. You can install pointblank 0.3 from CRAN with:\ninstall.packages(\u0026quot;pointblank\u0026quot;) The design goals of pointblank are to enable two important data validation workflows with a common set of validation step functions, and, to have the code work seamlessly with data in local data tables and with database tables.\nThe two dominant workflows that pointblank enables are:\ndata quality reporting pipeline-based data validation  The first workflow is concerned with the data quality of the target table. One would use validation step functions to create a validation plan. That plan results in an interrogation of the table data. Finally, we get a report of the interrogation to ascertain data quality. The key is to use a large number of validation step functions to reveal inconsistencies or errors in the table.\nThe second workflow is useful in a data-transformation pipeline that uses tabular data. The validation functions are used directly with data to either warn us of unforeseen data integrity problems or to completely stop the pipeline. Stopping is a good idea when dependent, downstream processes (that would use the data to some extent) would be compromised by bad data. Both workflows use a common set of validation step functions, ‘action levels’ (i.e., failure thresholds) can be set in a stepwise manner. Additionally, we can choose to use our own R functions to create side effects like logging.\nBoth workflows make use of a large collection of simple validation step functions. These functions are named such that it’s obvious what the validation does. For example, the col_vals_gt() function tests whether cell values in a column are greater than a specified value. The interface for each step function is consistent but also optimized for the particular operation.\nA Walkthrough of pointblank in the Data Quality Reporting Workflow To determine the level of data quality for a table we use something called an agent. It develops a validation plan, performs the interrogation, and holds information about that interrogation (we would then ask for a report). The create_agent() function is used to create the agent. The target table is given to the agent and the table can be a tibble or a tbl_dbi object that’s made through a database connection and the dplyr::tbl() function.\nWe use validation step functions to build a validation plan. There are 23 of them and some check for the existence or the type of column (col_exists() or the group of col_is_*() functions) whereas others perform a check in each table cell within a column (e.g., all of the col_vals_*() functions). We apply our own understanding of the data in the target table when using the pointblank step functions, and, we use as many as is necessary for adequate testing.\nAfter using validation step functions to create a validation plan, the interrogate() function should then be used. With that, the table will be interrogated and the necessary validation information will be stored in the agent.\nThe pointblank package contains a dataset called small_table which is indeed small but ideal for simple examples:\nsmall_table #\u0026gt; # A tibble: 13 x 8 #\u0026gt; date_time date a b c d e f #\u0026gt; \u0026lt;dttm\u0026gt; \u0026lt;date\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 2016-01-04 11:00:00 2016-01-04 2 1-bcd-345 3 3423. TRUE high #\u0026gt; 2 2016-01-04 00:32:00 2016-01-04 3 5-egh-163 8 10000. TRUE low #\u0026gt; 3 2016-01-05 13:32:00 2016-01-05 6 8-kdg-938 3 2343. TRUE high #\u0026gt; 4 2016-01-06 17:23:00 2016-01-06 2 5-jdo-903 NA 3892. FALSE mid #\u0026gt; 5 2016-01-09 12:36:00 2016-01-09 8 3-ldm-038 7 284. TRUE low #\u0026gt; 6 2016-01-11 06:15:00 2016-01-11 4 2-dhe-923 4 3291. TRUE mid #\u0026gt; 7 2016-01-15 18:46:00 2016-01-15 7 1-knw-093 3 843. TRUE high #\u0026gt; 8 2016-01-17 11:27:00 2016-01-17 4 5-boe-639 2 1036. FALSE low #\u0026gt; 9 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 10 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 11 2016-01-26 20:07:00 2016-01-26 4 2-dmx-010 7 834. TRUE low #\u0026gt; 12 2016-01-28 02:51:00 2016-01-28 2 7-dmx-010 8 108. FALSE low #\u0026gt; 13 2016-01-30 11:23:00 2016-01-30 1 3-dka-303 NA 2230. TRUE high  The validation plan for this table uses the following assertions:\nthe date_time column is a POSIXct date-time column column f contains only the values \"low\", \"mid\", and \"high\" the values in column a are all less than 10 The strings in column b conform to a specified regex pattern column d has values in the range of 0 to 5000 (this is not entirely true!)  Here is the code for the above validation logic:\nagent \u0026lt;- small_table %\u0026gt;% create_agent() %\u0026gt;% col_is_posix(vars(date_time)) %\u0026gt;% col_vals_in_set(vars(f), set = c(\u0026quot;low\u0026quot;, \u0026quot;mid\u0026quot;, \u0026quot;high\u0026quot;)) %\u0026gt;% col_vals_lt(vars(a), value = 10) %\u0026gt;% col_vals_regex(vars(b), regex = \u0026quot;^[0-9]-[a-z]{3}-[0-9]{3}$\u0026quot;) %\u0026gt;% col_vals_between(vars(d), left = 0, right = 5000) %\u0026gt;% interrogate() The agent object gives us a little bit of information about how the interrogation went:\nagent #\u0026gt; pointblank agent // \u0026lt;agent_2020-01-13_04:14:09\u0026gt; #\u0026gt; #\u0026gt; number of validation steps: 5 #\u0026gt; #\u0026gt; interrogation (2020-01-13 04:14:09) resulted in: #\u0026gt; - 4 passing validations #\u0026gt; - 1 failing validation more info: `get_agent_report()` The 4 passing validations means that all of the individual validations in four validation steps passed without any errors. One validation step failed with at least one test unit failing (each cell tested is equivalent to 1 test unit). We can generate a report with more detail by using get_agent_report():\nget_agent_report(agent) The report is a gt table, which is printed by default if we have the gt package installed (use remotes::install_github(\"rstudio/gt\") to install that package). The first five columns of the report are recognizable since they are names of the validation step functions and their parameters. The preconditions? column indicates whether the table was altered just before interrogation (for that validation step). The Units column shows us the total number of test units for each validation step. The n_pass column gives the number of passing test units while the f_pass column indicates the fraction of passing test units. The W, S, N indicators tell us whether we have entered either of the WARN, STOP, or NOTIFY states for these validation steps. Because we didn’t set any threshold levels for these states, they are irrelevant for this report. Finally, the Extract indicator tells us whether there are data extracts available for failed test units. For step 5, the col_vals_between() validation step, there is a data extract available. We can have a look at that extract with get_data_extracts():\nget_data_extracts(agent, i = 5) #\u0026gt; # A tibble: 1 x 8 #\u0026gt; date_time date a b c d e f #\u0026gt; \u0026lt;dttm\u0026gt; \u0026lt;date\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 2016-01-04 00:32:00 2016-01-04 3 5-egh-163 8 10000. TRUE low Recall that validation step 5 asserted that all values in column d should be between 0 and 5000, however, this extract of small_table shows that column d has a value that lies outside this specified range.\nA Walkthrough of pointblank in the Pipeline-based Data Validation Workflow The second workflow, pipeline-based data validations, somewhat simplifies the process for checking data directly. There is no agent involved here and we instead call validation step functions directly on the data table objects. Because there isn’t an agent, there won’t be a report either. The idea is that the side effects are most important here (the data will pass through the validation functions unchanged). We can trigger warnings, raise errors, or write out logs when exceeding specified failure thresholds.\nWhere would we do this? When importing data we could test that data by passing it through a few validation step functions with warn_at and stop_at threshold levels set. If we were to transform a data table, we could likewise use a set of validation step functions as a QA/QC measure. If bad data quality might be bad for a downstream data product, it’s probably better to stop the process through pointblank validation tests and then do root-cause analysis to fix the data quality problem.\nLet’s use the statements from the previous example to work within the pipeline-based data validation workflow. In this case, we’ll use a simple call of the action_levels() function to generate the al object. It’s passed to the actions argument of every validaton step function. The setting implies that the pipeline will be stopped when there is a single test unit failure (with stop_at = 1).\n# Create an `action_levels` object, stopping the pipeline # if we get a single failing test unit al \u0026lt;- action_levels(stop_at = 1) small_table %\u0026gt;% col_is_posix(vars(date_time), actions = al) %\u0026gt;% col_vals_in_set(vars(f), set = c(\u0026quot;low\u0026quot;, \u0026quot;mid\u0026quot;, \u0026quot;high\u0026quot;), actions = al) %\u0026gt;% col_vals_lt(vars(a), value = 10, actions = al) %\u0026gt;% col_vals_regex(vars(b), regex = \u0026quot;^[0-9]-[a-z]{3}-[0-9]{3}$\u0026quot;, actions = al) %\u0026gt;% col_vals_between(vars(d), left = 0, right = 5000, actions = al) Error: The validation (`col_vals_between()`) meets or exceeds the stop threshold This is one of those times when we might be glad to see an error. The threshold setting stopped the evaluation of the pipeline and, in turn, stops the running script if it’s deployed and automatically running on the regular. The action_levels() function is quite powerful and it allows us to define custom functions that are evaluated when entering each of the three failure states. In this type of workflow we don’t need to define those functions, pointblank will automatically do the sensible thing and provide a stock warning() or stop() message.\nWrapping Up These short demonstrations show the main features of the two data validation workflows of pointblank. There are many things you can do to precisely define the validation steps and to cause the correct action to occur when entering different failure states. I hope you’re inclined to try it out on your own data!\n La dernière version du package pointblank facilite la validation de vos données avec des workflows adaptés à vos besoins en matière de qualité des données. Vous pouvez installer pointblank 0.3 avec:\ninstall.packages(\u0026quot;pointblank\u0026quot;) L’objectif de conception de pointblank est de permettre deux workflows de validation de données importants avec un ensemble commun de fonctions d’étape de validation et le code écrit devrait fonctionner de manière transparente avec les données des tables de données locales et avec les données des bases de données.\nLes deux workflows dominants que permet pointblank sont:\nrapports sur la qualité des données validations de données basées sur le pipeline  Le premier workflow concerne la qualité des données de la table cible. On utiliserait des fonctions d’étape de validation pour créer un plan de validation. Ce plan entraîne une interrogation des données de la table. Enfin, nous obtenons un rapport de l’interrogation pour vérifier la qualité des données. L’idée principale est d’utiliser un grand nombre de fonctions d’étape de validation pour révéler des incohérences ou des erreurs dans le tableau de données.\nLa deuxième méthodologie est utile dans un pipeline de transformation de données qui utilise des données tabulaires. Les fonctions de validation sont utilisées directement pour nous avertir des problèmes imprévus d’intégrité des données ou pour arrêter complètement le pipeline. L’arrêt est une bonne idée lorsque les processus dépendants et en aval (qui utiliseraient les données dans une certaine mesure) seraient compromis par de mauvaises données. Les deux méthodologies utilisent un ensemble commun de fonctions d’étape de validation, les «action levels» (c’est-à-dire les seuils d’échec) peuvent être définis par étapes. De plus, nous pouvons choisir d’utiliser nos propres fonctions R pour créer des effets secondaires comme la journalisation.\nLes deux workflows utilisent une large collection de fonctions d’étape de validation simples. Ces fonctions sont nommées de telle sorte que la fonction de validation soit évidente. Par exemple, la fonction col_vals_gt() teste si les valeurs de cellule dans une colonne sont supérieures à une valeur spécifiée. L’interface pour chaque fonction d’étape est cohérente mais également optimisée pour l’opération particulière.\nPrésentation pas à pas de pointblank dans le workflow de rapport sur la qualité des données Pour déterminer le niveau de qualité des données d’une table, nous utilisons ce que l’on appelle un agent. Il élabore un plan de validation, effectue l’interrogatoire et détient des informations sur cette interrogation (nous demanderions alors un rapport). La fonction create_agent() est utilisée pour créer l’agent. La table cible est donnée à l’agent et la table peut être un tibble ou un objet tbl_dbi créé via une connexion à la base de données et la fonction dplyr::tbl().\nNous utilisons des fonctions d’étape de validation pour construire un plan de validation. Il y en a 23 et certains vérifient l’existence ou le type de colonne (col_exists() ou le groupe de fonctions de la forme: col_is_*()) tandis que d’autres effectuent une vérification dans chaque cellule du tableau d’une colonne (par exemple, tous les col_vals_*() fonctions). Nous appliquons notre propre compréhension des données de la table cible lors de l’utilisation des fonctions d’étape de pointblank, et nous en utilisons autant que nécessaire pour des tests adéquats.\nAprès avoir utilisé les fonctions de l’étape de validation pour créer un plan de validation, la fonction interrogate() doit ensuite être utilisée. Avec cela, la table sera interrogée et les informations de validation nécessaires seront stockées dans l’agent.\nUtilisons l’objet small_table pour des exemples:\nsmall_table #\u0026gt; # A tibble: 13 x 8 #\u0026gt; date_time date a b c d e f #\u0026gt; \u0026lt;dttm\u0026gt; \u0026lt;date\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 2016-01-04 11:00:00 2016-01-04 2 1-bcd-345 3 3423. TRUE high #\u0026gt; 2 2016-01-04 00:32:00 2016-01-04 3 5-egh-163 8 10000. TRUE low #\u0026gt; 3 2016-01-05 13:32:00 2016-01-05 6 8-kdg-938 3 2343. TRUE high #\u0026gt; 4 2016-01-06 17:23:00 2016-01-06 2 5-jdo-903 NA 3892. FALSE mid #\u0026gt; 5 2016-01-09 12:36:00 2016-01-09 8 3-ldm-038 7 284. TRUE low #\u0026gt; 6 2016-01-11 06:15:00 2016-01-11 4 2-dhe-923 4 3291. TRUE mid #\u0026gt; 7 2016-01-15 18:46:00 2016-01-15 7 1-knw-093 3 843. TRUE high #\u0026gt; 8 2016-01-17 11:27:00 2016-01-17 4 5-boe-639 2 1036. FALSE low #\u0026gt; 9 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 10 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 11 2016-01-26 20:07:00 2016-01-26 4 2-dmx-010 7 834. TRUE low #\u0026gt; 12 2016-01-28 02:51:00 2016-01-28 2 7-dmx-010 8 108. FALSE low #\u0026gt; 13 2016-01-30 11:23:00 2016-01-30 1 3-dka-303 NA 2230. TRUE high  Le plan de validation de ce tableau utilise les assertions suivantes:\nla colonne date_time est une colonne date-heure la colonne f ne contient que les valeurs \"low\", \"mid\", and \"high\" les valeurs de la colonne a sont toutes inférieures à 10 Les valeurs de texte dans la colonne b sont conformes à un modèle spécifié la colonne d a des valeurs entre 0 et 5000 (pas entièrement vrai!)  Voici le code pour la validation:\nagent \u0026lt;- small_table %\u0026gt;% create_agent() %\u0026gt;% col_is_posix(vars(date_time)) %\u0026gt;% col_vals_in_set(vars(f), set = c(\u0026quot;low\u0026quot;, \u0026quot;mid\u0026quot;, \u0026quot;high\u0026quot;)) %\u0026gt;% col_vals_lt(vars(a), value = 10) %\u0026gt;% col_vals_regex(vars(b), regex = \u0026quot;^[0-9]-[a-z]{3}-[0-9]{3}$\u0026quot;) %\u0026gt;% col_vals_between(vars(d), left = 0, right = 5000) %\u0026gt;% interrogate() L’objet agent nous donne quelques informations sur la façon dont les choses se sont passées:\nagent #\u0026gt; pointblank agent // \u0026lt;agent_2020-01-13_04:14:09\u0026gt; #\u0026gt; #\u0026gt; number of validation steps: 5 #\u0026gt; #\u0026gt; interrogation (2020-01-13 04:14:09) resulted in: #\u0026gt; - 4 passing validations #\u0026gt; - 1 failing validation more info: `get_agent_report()` Les «4 passing validations» signifient que toutes les validations individuelles en quatre étapes de validation ont réussi sans erreur. Une étape de validation a échoué et au moins une unité de test a échoué (chaque cellule testée équivaut à 1 unité de test). Nous pouvons générer un rapport avec plus de détails en utilisant get_agent_report():\nget_agent_report(agent) Le rapport est une table gt, qui est imprimée par défaut si nous avons installé le paquet gt (utilisez remotes::install_github(\"rstudio/gt\") pour installer ce paquet). Les cinq premières colonnes du rapport sont reconnaissables car ce sont les noms des fonctions de l’étape de validation et leurs paramètres. Les preconditions colonne indique si la table a été modifiée juste avant l’interrogation (pour cette étape de validation). La colonne Units nous indique le nombre total d’unités de test pour chaque étape de validation. La colonne n_pass donne le nombre d’unités de test réussies tandis que la colonne f_pass indique la fraction d’unités de test réussies. Les indicateurs W, S, N nous indiquent si nous sommes entrés dans l’un des états WARN, STOP ou NOTIFY pour ces étapes de validation. Étant donné que nous n’avons défini aucun seuil pour ces États, ils ne sont pas pertinents pour ce rapport. Enfin, l’indicateur Extract nous indique si des extraits de données sont disponibles pour les unités de test ayant échoué. Pour l’étape 5, l’étape de validation col_vals_between(), un extrait de données est disponible. Nous pouvons jeter un œil à cet extrait avec get_data_extracts():\nget_data_extracts(agent, i = 5) #\u0026gt; # A tibble: 1 x 8 #\u0026gt; date_time date a b c d e f #\u0026gt; \u0026lt;dttm\u0026gt; \u0026lt;date\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 2016-01-04 00:32:00 2016-01-04 3 5-egh-163 8 10000. TRUE low Rappelons que l'étape 5 a affirmé que toutes les valeurs de la colonne d doivent être comprises entre 0 et 5000, cependant, cet extrait de small_table montre que la colonne d a une valeur qui se situe en dehors de cette plage spécifiée.\nProcédure pas à pas de pointblank dans le workflow de validation des données basé sur le pipeline La deuxième méthodologie, la validation des données par pipeline, simplifie quelque peu le processus de vérification directe des données. Aucun agent n’est impliqué ici et nous appelons plutôt les fonctions d’étape de validation directement sur les objets de la table de données. Parce qu’il n’y a pas d’agent, il n’y aura pas non plus de rapport. L’idée est que les effets secondaires sont les plus importants ici (les données passeront par les fonctions de validation inchangées). Nous pouvons déclencher des avertissements, générer des erreurs ou écrire des journaux en cas de dépassement des seuils d’échec spécifiés.\nOù ferions-nous cela? Lors de l’importation de données, nous pourrions tester ces données en les passant par quelques fonctions d’étape de validation avec des niveaux de seuil warn_at et stop_at définis. Si nous devions transformer un tableau de données, nous pourrions également utiliser un ensemble de fonctions d’étape de validation comme mesure d’AQ et de CQ. Si la mauvaise qualité des données peut être mauvaise pour un produit de données en aval, il est probablement préférable d’arrêter le processus par le biais de tests de validation pointblank, puis d’effectuer une analyse des causes profondes pour résoudre le problème de qualité des données.\nUtilisons les instructions de l’exemple précédent pour travailler dans le workflow de validation des données basé sur le pipeline. Dans ce cas, nous utiliserons un simple appel de la fonction action_levels() pour générer l’objet al. Il est passé à l’argument actions de chaque fonction d’étape de validation. Le paramètre implique que le pipeline sera arrêté en cas de défaillance d’une seule unité de test (avec stop_at = 1).\n# Create an `action_levels` object, stopping the pipeline # if we get a single failing test unit al \u0026lt;- action_levels(stop_at = 1) small_table %\u0026gt;% col_is_posix(vars(date_time), actions = al) %\u0026gt;% col_vals_in_set(vars(f), set = c(\u0026quot;low\u0026quot;, \u0026quot;mid\u0026quot;, \u0026quot;high\u0026quot;), actions = al) %\u0026gt;% col_vals_lt(vars(a), value = 10, actions = al) %\u0026gt;% col_vals_regex(vars(b), regex = \u0026quot;^[0-9]-[a-z]{3}-[0-9]{3}$\u0026quot;, actions = al) %\u0026gt;% col_vals_between(vars(d), left = 0, right = 5000, actions = al) Error: The validation (`col_vals_between()`) meets or exceeds the stop threshold C’est l’un de ces moments où nous pourrions être super heureux de voir une erreur. Le paramètre de seuil a arrêté l’évaluation du pipeline et, à son tour, arrête le script en cours d’exécution s’il est déployé et s’exécute automatiquement sur la version standard. La fonction action_levels() est assez puissante et elle nous permet de définir des fonctions personnalisées qui sont évaluées lors de la saisie de chacun des trois états de défaillance. Dans ce type de workflow, nous n’avons pas besoin de définir ces fonctions, pointblank nous aidera automatiquement à cela.\nEssayez pointblank! Ces courtes démonstrations présentent les principales caractéristiques des deux workflows de validation des données de pointblank. Il existe de nombreuses choses que vous pouvez faire pour définir précisément les étapes de validation et pour que l’action correcte se produise lors de la saisie de différents états de défaillance. J’espère que vous êtes enclin à l’essayer sur vos propres données!\n Die neueste Version des pointblank-Pakets erleichtert die Validierung Ihrer Daten mit Workflows, die auf Ihre Datenqualitätsanforderungen abgestimmt sind. Sie können pointblank 0.3 von CRAN installieren mit:\ninstall.packages(\u0026quot;pointblank\u0026quot;) Das Entwurfsziel von pointblank besteht darin, zwei wichtige Datenvalidierungs-Workflows mit einem gemeinsamen Satz von Validierungsschrittfunktionen zu ermöglichen. Der geschriebene Code sollte mit Daten in lokalen Datentabellen und mit Daten in Datenbanken gleichermaßen gut funktionieren.\nDie beiden wichtigsten Workflows, bei denen pointblank hilft, sind:\nBerichterstattung zur Datenqualität Pipeline-basierte Datenvalidierungen  Der erste Workflow befasst sich mit der Datenqualität der Zieltabelle. Man würde Validierungsschrittfunktionen verwenden, um einen Validierungsplan zu erstellen. Dieser Plan führt zu einer Abfrage der Tabellendaten. Schließlich erhalten wir einen Bericht über die Abfrage, um die Datenqualität festzustellen. Es wird empfohlen, eine große Anzahl von Validierungsschrittfunktionen zu verwenden. Mit mehr von ihnen können wir Inkonsistenzen oder Fehler in der Tabelle besser aufdecken.\nDer zweite Workflow ist in einer Datentransformationspipeline nützlich, die Tabellendaten verwendet. Die Validierungsfunktionen werden direkt verwendet, um uns entweder vor unvorhergesehenen Problemen mit der Datenintegrität zu warnen oder um die Pipeline vollständig zu stoppen. Anhalten ist eine gute Idee, wenn abhängige, nachgelagerte Prozesse (die die Daten in gewissem Umfang nutzen würden) durch schlechte Daten beeinträchtigt würden. Beide Workflows verwenden einen gemeinsamen Satz von Validierungsschrittfunktionen. “Action levels” (d. H. Fehlerschwellen) können schrittweise festgelegt werden. Zusätzlich können wir unsere eigenen R-Funktionen verwenden, um Nebenwirkungen wie das Schreiben von Protokolldateien zu erzeugen.\nBeide Workflows verwenden eine große Sammlung einfacher Validierungsschrittfunktionen. Diese Funktionen werden so benannt, dass es offensichtlich ist, was die Validierung bewirkt. Beispielsweise testet die Funktion col_vals_gt(), ob die Zellenwerte in einer Spalte größer als ein angegebener Wert sind. Die Schnittstelle für jede Schrittfunktion ist konsistent, aber auch für die jeweilige Operation optimiert.\nExemplarische Vorgehensweise von pointblank im Workflow für die Berichterstellung zur Datenqualität Um die Datenqualität für eine Tabelle zu bestimmen, verwenden wir einen Agenten. Es entwickelt einen Validierungsplan, führt die Befragung durch und enthält Informationen zu dieser Befragung (wir würden dann um einen Bericht bitten). Mit der Funktion create_agent() wird der Agent erstellt. Die Zieltabelle wird dem Agenten übergeben, und die Tabelle kann ein tibble- oder ein tbl_dbi-Objekt sein, das über eine Datenbankverbindung und die Funktion dplyr::tbl() erstellt wurde.\nWir verwenden Validierungsschrittfunktionen, um einen Validierungsplan zu erstellen. Es gibt 23 von ihnen und einige prüfen die Existenz oder den Typ der Spalte (col_exists() oder die Gruppe von col_is_*() -Funktionen), während andere eine Prüfung in jeder Tabellenzelle innerhalb einer Spalte durchführen (z. B. alle col_vals_*() Funktionen). Wir wenden bei der Verwendung der Pointblank-Step-Funktionen unser eigenes Verständnis der Daten in der Zieltabelle an und verwenden so viele, wie für angemessene Tests erforderlich sind.\nNachdem Sie Validierungsschrittfunktionen zum Erstellen eines Validierungsplans verwendet haben, sollte die Funktion interrogate() verwendet werden. Damit wird die Tabelle abgefragt und die notwendigen Validierungsinformationen im Agenten gespeichert.\nDas pointblank-Paket enthält einen Datensatz mit dem Namen small_table. Wir werden es für alle kommenden Beispiele verwenden:\nsmall_table #\u0026gt; # A tibble: 13 x 8 #\u0026gt; date_time date a b c d e f #\u0026gt; \u0026lt;dttm\u0026gt; \u0026lt;date\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 2016-01-04 11:00:00 2016-01-04 2 1-bcd-345 3 3423. TRUE high #\u0026gt; 2 2016-01-04 00:32:00 2016-01-04 3 5-egh-163 8 10000. TRUE low #\u0026gt; 3 2016-01-05 13:32:00 2016-01-05 6 8-kdg-938 3 2343. TRUE high #\u0026gt; 4 2016-01-06 17:23:00 2016-01-06 2 5-jdo-903 NA 3892. FALSE mid #\u0026gt; 5 2016-01-09 12:36:00 2016-01-09 8 3-ldm-038 7 284. TRUE low #\u0026gt; 6 2016-01-11 06:15:00 2016-01-11 4 2-dhe-923 4 3291. TRUE mid #\u0026gt; 7 2016-01-15 18:46:00 2016-01-15 7 1-knw-093 3 843. TRUE high #\u0026gt; 8 2016-01-17 11:27:00 2016-01-17 4 5-boe-639 2 1036. FALSE low #\u0026gt; 9 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 10 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 11 2016-01-26 20:07:00 2016-01-26 4 2-dmx-010 7 834. TRUE low #\u0026gt; 12 2016-01-28 02:51:00 2016-01-28 2 7-dmx-010 8 108. FALSE low #\u0026gt; 13 2016-01-30 11:23:00 2016-01-30 1 3-dka-303 NA 2230. TRUE high  Der Validierungsplan für diese Tabelle verwendet die folgenden Zusicherungen:\nDie Spalte date_time ist eine Datum-Uhrzeit-Spalte Spalte f enthält nur die Werte \"low\", \"mid\" und \"high\" Die Werte in Spalte a sind alle kleiner als 10 Die Zeichenfolgen in Spalte b entsprechen einem angegebenen regulären Ausdruck Spalte d hat Werte im Bereich von 0 bis 5000 (dies ist nicht ganz richtig!)  Hier ist der Code für die obige Validierungslogik:\nagent \u0026lt;- small_table %\u0026gt;% create_agent() %\u0026gt;% col_is_posix(vars(date_time)) %\u0026gt;% col_vals_in_set(vars(f), set = c(\u0026quot;low\u0026quot;, \u0026quot;mid\u0026quot;, \u0026quot;high\u0026quot;)) %\u0026gt;% col_vals_lt(vars(a), value = 10) %\u0026gt;% col_vals_regex(vars(b), regex = \u0026quot;^[0-9]-[a-z]{3}-[0-9]{3}$\u0026quot;) %\u0026gt;% col_vals_between(vars(d), left = 0, right = 5000) %\u0026gt;% interrogate() Das Agent-Objekt gibt uns ein paar Informationen über die Befragung:\nagent #\u0026gt; pointblank agent // \u0026lt;agent_2020-01-13_04:14:09\u0026gt; #\u0026gt; #\u0026gt; number of validation steps: 5 #\u0026gt; #\u0026gt; interrogation (2020-01-13 04:14:09) resulted in: #\u0026gt; - 4 passing validations #\u0026gt; - 1 failing validation more info: `get_agent_report()` Die 4 passing validations bedeuten, dass alle Einzelvalidierungen in vier Validierungsschritten fehlerfrei bestanden wurden. Ein Validierungsschritt ist fehlgeschlagen, wobei mindestens eine Testeinheit ausgefallen ist (jede getestete Zelle entspricht 1 Testeinheit). Mit get_agent_report() können wir einen detaillierteren Bericht erstellen:\nget_agent_report(agent) Der Bericht ist eine gt-Tabelle, die standardmäßig gedruckt wird, wenn das gt-Paket installiert ist (verwenden Sie remotes::install_github(\"rstudio/gt\"), um dieses Paket zu installieren). Die ersten fünf Spalten des Berichts sind erkennbar, da sie Namen der Validierungsschrittfunktionen und ihrer Parameter sind. Die Spalte preconditions? gibt an, ob die Tabelle unmittelbar vor der Abfrage geändert wurde (für diesen Validierungsschritt). In der Spalte Units wird die Gesamtzahl der Testeinheiten für jeden Validierungsschritt angezeigt. Die Spalte n_pass gibt die Anzahl der bestandenen Testeinheiten an, während die Spalte f_pass den Anteil der bestandenen Testeinheiten angibt. Die W-, S- und N-Anzeigen zeigen an, ob wir für diese Überprüfungsschritte einen der Zustände WARN, STOP oder NOTIFY eingegeben haben. Da wir für diese Staaten keine Schwellenwerte festgelegt haben, sind sie für diesen Bericht nicht relevant. Schließlich gibt der Indikator Extract Auskunft darüber, ob für fehlerhafte Testeinheiten Datenextrakte verfügbar sind. Für step 5, den Validierungsschritt col_vals_between(), steht ein Datenextrakt zur Verfügung. Wir können uns diesen Auszug mit get_data_extracts() ansehen:\nget_data_extracts(agent, i = 5) #\u0026gt; # A tibble: 1 x 8 #\u0026gt; date_time date a b c d e f #\u0026gt; \u0026lt;dttm\u0026gt; \u0026lt;date\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 2016-01-04 00:32:00 2016-01-04 3 5-egh-163 8 10000. TRUE low Denken Sie daran, dass bei der Validierung in step 5 festgestellt wurde, dass alle Werte in Spalte d zwischen 0 und 5000 liegen sollten. Dieser Auszug aus small_table zeigt jedoch, dass Spalte d einen Wert hat, der außerhalb des angegebenen Bereichs liegt.\nEine exemplarische Vorgehensweise für pointblank im Pipeline-basierten Datenüberprüfungs-Workflow Der zweite Workflow, die pipelinebasierte Datenüberprüfung, vereinfacht die direkte Überprüfung der Daten ein wenig. Hier ist kein Agent beteiligt. Stattdessen rufen wir Validierungsschrittfunktionen direkt auf den Datentabellenobjekten auf. Da es keinen Agenten gibt, wird es auch keinen Bericht geben. Die Idee ist, dass die Nebenwirkungen hier am wichtigsten sind (die Daten durchlaufen die Validierungsfunktionen unverändert). Wir können Warnungen auslösen, Fehler auslösen oder Protokolle ausschreiben, wenn bestimmte Fehlerschwellen überschritten werden.\nWo würden wir das machen? Beim Importieren von Daten konnten wir diese Daten testen, indem wir einige Validierungsschrittfunktionen mit festgelegten Schwellenwerten für warn_at und stop_at durchliefen. Wenn wir eine Datentabelle transformieren würden, könnten wir ebenfalls eine Reihe von Validierungsschrittfunktionen als QA / QC-Maß verwenden. Wenn eine schlechte Datenqualität für ein nachgeschaltetes Datenprodukt schlecht sein könnte, ist es wahrscheinlich besser, den Prozess durch pointblank-Validierungstests zu stoppen und anschließend eine Ursachenanalyse durchzuführen, um das Datenqualitätsproblem zu beheben.\nVerwenden Sie die Anweisungen aus dem vorherigen Beispiel, um im Workflow für die pipelinebasierte Datenüberprüfung zu arbeiten. In diesem Fall verwenden wir einen einfachen Aufruf der action_levels() -Funktion, um das al-Objekt zu generieren. Es wird an das Argument actions jeder Validierungsschrittfunktion übergeben. Die Einstellung impliziert, dass die Pipeline gestoppt wird, wenn eine einzelne Testeinheit ausfällt (mit stop_at = 1).\n# Create an `action_levels` object, stopping the pipeline # if we get a single failing test unit al \u0026lt;- action_levels(stop_at = 1) small_table %\u0026gt;% col_is_posix(vars(date_time), actions = al) %\u0026gt;% col_vals_in_set(vars(f), set = c(\u0026quot;low\u0026quot;, \u0026quot;mid\u0026quot;, \u0026quot;high\u0026quot;), actions = al) %\u0026gt;% col_vals_lt(vars(a), value = 10, actions = al) %\u0026gt;% col_vals_regex(vars(b), regex = \u0026quot;^[0-9]-[a-z]{3}-[0-9]{3}$\u0026quot;, actions = al) %\u0026gt;% col_vals_between(vars(d), left = 0, right = 5000, actions = al) Error: The validation (`col_vals_between()`) meets or exceeds the stop threshold Dies ist eine der Situationen, in denen wir uns möglicherweise über einen Fehler freuen. Die Schwellenwerteinstellung hat die Auswertung der Pipeline gestoppt und stoppt das ausgeführte Skript, wenn es bereitgestellt wird und automatisch regelmäßig ausgeführt wird. Die action_levels()-Funktion ist sehr leistungsfähig und ermöglicht es uns, benutzerdefinierte Funktionen zu definieren, die beim Eingeben der drei Fehlerzustände ausgewertet werden. In dieser Art von Workflow müssen diese Funktionen nicht definiert werden. Pointblank erledigt automatisch die sinnvolle Aufgabe und gibt eine warning() oder eine stop()-Meldung aus.\nBitte testen Sie das pointblank-Paket Diese kurzen Demonstrationen zeigen die Hauptmerkmale der beiden Datenvalidierungs-Workflows von pointblank. Es gibt viele Möglichkeiten, um die Überprüfungsschritte genau zu definieren und die richtige Aktion auszulösen, wenn verschiedene Fehlerzustände eingegeben werden. Ich hoffe, Sie sind geneigt, es an Ihren eigenen Daten auszuprobieren!\n  function openLang(evt, cityName) { var i, tabcontent, tablinks; tabcontent = document.getElementsByClassName(\"tabcontent\"); for (i = 0; i ","date":1578873600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578894083,"objectID":"aa10b734f8d65608a1364dd6e4d12dd8","permalink":"/post/pointblank-0-3/","publishdate":"2020-01-13T00:00:00Z","relpermalink":"/post/pointblank-0-3/","section":"post","summary":"There is a new release of the **pointblank** package. It tries to prove that assessing data quality does *not* have to be difficult.","tags":["R Packages"],"title":"pointblank v0.3","type":"post"},{"authors":[],"categories":[],"content":"    English  French  German    The newest release of the blastula package lets you to do amazing things with HTML email in R and RStudio Connect. You can install blastula 0.3 from CRAN with:\ninstall.packages(\u0026quot;blastula\u0026quot;) This is a huge release! There are so many new and improved features we won’t be able to get through all of them here. Let’s focus on just two: R Markdown report emailing and improved HTML emailing using SMTP.\nR Markdown Report Emailing via RStudio Connect The capability to email a rendered R Markdown document in RStudio Connect has been available for well over a year. What would happen is that the report would be in the form of an attachment and message portion of the email would be prepared largely by RStudio Connect. With blastula v0.3, we can now create an email message body directly with R Markdown. Moreover, we can have a ‘main’ report for RStudio Connect viewers (with all of the details) and an ‘email’ version of the report that contains only the necessary elements for the purposes of email.\nStatic elements like ggplots and images can be part of the R Markdown email. The contents are faithfully converted to an HTML email message body that is fully responsive, so it’ll look great on both larger displays and on mobile devices. We went to great lengths to test and ensure that received emails display without problems on dozens of email clients.\nIf you thought that emailing R Markdown reports from RStudio Connect was a bit more difficult than should be, you’ll like this next part. There is now an easier-to-use methodology for associating an email to a published R Markdown report. The function prepare_rsc_example_files() is included to generate a set of example files relevant to R Markdown emailing in RStudio Connect. It provides a working example of a main .Rmd document, an email .Rmd document, and a CSV file that can be included as an attachment (any files generated from the main .Rmd document can also be attached). Documentation that explains how these documents interact, which blastula functions are used, and how to publish to RSC, is available in the internal documentation for the attach_connect_email() function. An updated support document in the official RStudio Connect documentation is forthcoming.\nI’m pretty sure that RStudio Connect users and the recipients of these emails will love the changes implemented here. Expect further improvements to R Markdown emailing via RStudio Connect in future releases of blastula.\nImproved HTML Emailing Using SMTP RStudio Connect isn’t the only way to send emails with blastula. We can opt to send our own custom emails through an SMTP server we have access to (e.g., Gmail, Outlook, etc.). These are HTML emails that are, again, responsive to display size and have been well tested on dozens of email clients. Let’s quickly look at three things that have changed for the better with regard to email composition and SMTP sending.\nRevised message composition with improved security Previously, text interpolation features from the glue package were built into the compose_email() function. This means we could have used the string \"The date and time of sending is {Sys.time()}.\" directly as input to, say, the message footer. Having the potential for R evaluation in strings invites security risks, so, this is no longer possible. Instead, we can simply opt to use glue::glue() ourselves or paste(). When there is any Markdown or HTML element, the md() function is required. Here is an example of a simple message that uses Markdown:\nemail \u0026lt;- compose_email( body = md( \u0026quot; ## Hello! This is an email message that was generated by the blastula package. Yep, we can use **Markdown** formatting but be sure to use the `md()` function. Here is a link to a great song ([E-MAIL ME!](https://youtu.be/-FcJbEg3vX8)). Cheers, The blastula team \u0026quot;), footer = md( \u0026quot; sent via the [blastula](https://rich-iannone.github.io/blastula) R package \u0026quot;) )  We can always preview the email object in the RStudio Viewer while getting the composition just right. For more details on email message composition with compose_email(), have a look at the Simple Email Composition article on the project website.\nNo external software to install for SMTP sending In the few years that blastula has been available, it relied on various pieces of external software for sending email. Not anymore. This release favors the creation of an RFC-2822 email body, sending through the excellent curl package. This all means that emails can now be sent dependably with the smtp_send() function on all the major platforms with no up-front installation of a third-party binary.\nImproved credentials handling The package now ships with functions for setting up and retrieving SMTP configuration and credentials information. We can set this in the system-wide key-value store with create_smtp_creds_key(). With such a key added, the credentials helper creds_key() can be used when sending email through smtp_send(). Alternatively, a credentials file can be created using the create_smtp_creds_file() function (retrieved with the creds_file() credentials helper). Lastly, credentials can be fully specified at the time of sending with the creds() function. Whenever a password is needed for setup, a prompt will appear for password entry and the password text will be obscured.\nMore! Other quality-of-life improvements include automatic image embedding (via Base64 encoding) from the use of the add_image() and add_ggplot() functions when used in conjunction with compose_email(). There’s the option for automatic image deployment and retrieval of the external image tag through the add_imgur_image() function. Finally, there is a new set of block_*() functions that help us compose emails with more complex layouts.\nWrapping Up I hope that you try out the new release of the blastula package. So many useful things can be created with R and having the means to deliver our findings through email is super satisfying both for the sender and the recipient.\n La nouvelle version du package blastula vous permet de faire des choses sympas avec les e-mails HTML dans R et RStudio Connect. Installez blastula 0.3 de CRAN avec:\ninstall.packages(\u0026quot;blastula\u0026quot;) C’est une énorme sortie et donc il y a beaucoup de nouvelles choses… Je ne pense pas qu’il y ait assez de temps pour parler de tout ici. Mais ça va, regardons deux choses: envoyer des rapports par e-mail avec R Markdown et des e-mails HTML améliorés (via un serveur SMTP).\nEmailing R Markdown Rapports avec RStudio Connect La possibilité d’envoyer un document R Markdown rendu par e-mail est disponible depuis longtemps (dans RStudio Connect). Mais c’était en pièce jointe (un peu décevant). Avec le nouveau package blastula, nous pouvons désormais créer un e-mail entièrement avec R Markdown (le contenu va directement dans l’e-mail). De plus, nous pouvons avoir un rapport «principal» pour les téléspectateurs RStudio Connect (avec tous les détails) et une version «e-mail» du rapport qui contient uniquement les éléments nécessaires aux fins de l’e-mail. Ah… beaucoup mieux!\nLes éléments statiques tels que ggplots et les images peuvent faire partie de l’e-mail R Markdown. Le contenu est converti en un corps de message électronique HTML qui a fière allure sur les grands écrans et sur les téléphones cellulaires. Nous avons fait de grands efforts pour tester tout cela. Cela impliquait de consulter les e-mails de nombreux clients de messagerie.\nL’envoi de rapports R Markdown par RStudio Connect a été un peu difficile. Il est désormais plus facile d’associer un e-mail à un rapport R Markdown publié. La fonction prepare_rsc_example_files() peut être utilisée pour générer un ensemble d’exemples de fichiers. Ces fichiers montrent comment effectuer des e-mails R Markdown dans RStudio Connect. Les fichiers incluent un document .Rmd principal, un document .Rmd de courrier électronique et un fichier CSV qui peut être inclus en tant que pièce jointe. Pourquoi le CSV? Parce que tous les fichiers générés à partir du document principal .Rmd peuvent également être joints! La documentation qui explique comment ces documents interagissent, quelles fonctions blastula sont utilisées et comment publier sur RSC, est disponible dans la documentation interne de la fonction attach_connect_email().\nOuais. Je suis certain que les utilisateurs de RStudio Connect et les destinataires de ces e-mails adoreront les changements mis en œuvre ici. Nous apporterons plus de modifications aux e-mails R Markdown via RStudio Connect dans les prochaines versions de blastula.\nEmailing HTML amélioré à l’aide de SMTP RStudio Connect n’est pas le seul moyen d’envoyer des e-mails avec blastula. Nous pouvons envoyer des e-mails via un serveur SMTP auquel nous avons accès (par exemple, Gmail, Outlook, etc.). Voyons rapidement trois choses qui se sont améliorées en ce qui concerne la composition des e-mails et l’envoi SMTP.\nComposition des messages révisée avec plus de sécurité Auparavant, les fonctions d’interpolation de texte du package glue étaient intégrées à la fonction compose_email(). Cela signifie que nous aurions pu utiliser la déclaration \"The date and time of sending is {Sys.time()}.\" Directement comme entrée dans, disons, le pied de page du message. Le fait d’avoir le potentiel d’évaluation R dans les chaînes entraîne des risques de sécurité, ce n’est donc plus possible. Au lieu de cela, nous pouvons simplement choisir d’utiliser glue::glue() nous-mêmes ou paste(). Lorsqu’il y a un élément Markdown ou HTML, la fonction md() est requise. Voici un exemple de message simple qui utilise Markdown (c’est en anglais):\nemail \u0026lt;- compose_email( body = md( \u0026quot; ## Hello! This is an email message that was generated by the blastula package. Yep, we can use **Markdown** formatting but be sure to use the `md()` function. Here is a link to a great song ([E-MAIL ME!](https://youtu.be/-FcJbEg3vX8)). Cheers, The blastula team \u0026quot;), footer = md( \u0026quot; sent via the [blastula](https://rich-iannone.github.io/blastula) R package \u0026quot;) )  Nous pouvons toujours prévisualiser l’objet email dans la RStudio Viewer tout en obtenant la composition parfaite. Pour plus de détails sur la composition des e-mails avec compose_email(), consultez l’article Simple Email Composition sur le site web du projet.\nAucun logiciel externe n’est nécessaire pour envoyer des e-mails avec SMTP Au cours des quelques années où blastula a été disponible, il s’est appuyé sur divers logiciels externes pour envoyer des e-mails. Ce n’est plus vrai. Nous créons maintenant un corps d’e-mail RFC-2822 et envoyons des e-mails avec une fonction du package curl. Désormais, les e-mails peuvent désormais être envoyés de manière fiable avec la fonction smtp_send() sur toutes les principales plates-formes informatiques sans aucune dépendance difficile à installer.\nAmélioration de la gestion des informations d’identification Le package possède désormais des fonctions de configuration et de récupération des informations de configuration et d’informations d’identification SMTP. Nous pouvons configurer cela avec create_smtp_creds_key(). Avec une telle clé ajoutée, l’aide aux informations d’identification creds_key() peut être utilisée lors de l’envoi d’e-mails via smtp_send(). Alternativement, un fichier d’informations d’identification peut être créé en utilisant la fonction create_smtp_creds_file() (récupérée avec creds_file()). Enfin, les informations d’identification peuvent être entièrement spécifiées au moment de l’envoi avec la fonction creds(). Chaque fois qu’un mot de passe est nécessaire, une invite apparaîtra pour la saisie du mot de passe (le texte du mot de passe sera masqué).\nIl y a encore plus! D’autres changements incluent l’intégration automatique d’images (via l’encodage Base64) à partir de l’utilisation des fonctions add_image() et add_ggplot() lorsqu’elles sont utilisées avec compose_email(). La fonction add_imgur_image() facilite l’utilisation d’images externes dans les e-mails. Enfin, il existe un nouvel ensemble de fonctions block_*() qui nous aident à composer des e-mails avec des mises en page plus complexes.\nConclusion J’espère que vous essayez la nouvelle version du package blastula. Nous pouvons créer des choses utiles avec R et avoir les moyens de livrer nos résultats par e-mail est super cool pour l’expéditeur et le destinataire.\n Mit der neuen Version des blastula-Pakets können Sie in R und RStudio Connect coole Dinge mit HTML-E-Mails tun. Installieren Sie CRAN blastula 0.3 mit:\ninstall.packages(\u0026quot;blastula\u0026quot;) Dies ist ein ziemlich umfangreiches Software-Upgrade! Es gibt so viele neue und verbesserte Funktionen, dass wir sie hier nicht alle durcharbeiten können. Schauen wir uns zwei neue Themen an: R Markdown Bericht-E-Mail und verbessertes HTML-E-Mail mit SMTP.\nR Markdown E-Mail-Berichte mit RStudio Connect Die Möglichkeit, ein per E-Mail gesendetes R Markdown-Dokument zu senden, ist seit langem verfügbar (in RStudio Connect). Aber es war anhaftend (etwas enttäuschend). Mit dem neuen Blastula-Paket können wir jetzt eine E-Mail komplett mit R Markdown erstellen (der Inhalt geht direkt in die E-Mail). Außerdem können wir einen “Haupt”-Report für die Zuschauer RStudio Connect (mit allen Details) und eine “E-Mail”-Version des Berichts haben, die nur die für die Zwecke der E-Mail erforderlichen Elemente enthält. Viel besser!\nStatische Elemente wie ggplots und Bilder können Teil der R Markdown-E-Mail sein. Der Inhalt wird in einen HTML-Nachrichtentext konvertiert, der auf große Desktop-Displays und Handys großartig aussieht. Wir haben große Anstrengungen unternommen, um all dies zu testen. Dies beinhaltete das Betrachten der E-Mails vieler E-Mail-Clients.\nEs war ein bisschen schwierig, R Markdown von RStudio Connect zu melden. Es ist jetzt einfacher, eine E-Mail mit einem veröffentlichten R Markdown-Report zu verknüpfen. Die Funktion prepare_rsc_example_files() kann verwendet werden, um einen Satz von Beispieldateien zu generieren. Diese Dateien zeigen, wie R Markdown-E-Mails in RStudio Connect erstellt werden. Die Dateien enthalten ein Haupt-RMD-Dokument, ein RMD-E-Mail-Dokument und eine CSV-Datei, die als Anhang beigefügt werden kann. Warum die CSV? Denn alle Dateien, die aus dem Hauptdokument .Rmd generiert wurden, können auch angehängt werden! Die Dokumentation, die erklärt, wie diese Dokumente interagieren, welche blastula-Funktionen verwendet werden und wie sie in RSC veröffentlicht werden, finden Sie in der internen Dokumentation der Funktion attach_connect_email().\nJa. Ich bin sicher, dass RStudio Connect-Nutzer und -Empfänger dieser E-Mails die hier vorgenommenen Änderungen lieben werden. In zukünftigen Versionen von blastula werden wir weitere Änderungen an R Markdown-E-Mails über RStudio Connect vornehmen.\nErweitertes HTML-E-Mailing über SMTP RStudio Connect ist nicht die einzige Möglichkeit, E-Mails mit blastula zu versenden. Wir können E-Mails über einen SMTP-Server senden, auf den wir Zugriff haben (z. B. Google Mail, Outlook usw.). Schauen wir uns kurz drei Dinge an, die sich in Bezug auf die E-Mail-Zusammensetzung und den SMTP-Versand verbessert haben.\nÜberarbeitete Nachrichtenkomposition mit mehr Sicherheit Zuvor waren die Textinterpolationsfunktionen des glue-Pakets in die Funktion compose_email() integriert. Dies bedeutet, dass wir die Anweisung \"The date and time of sending is {Sys.time()}.\" Direkt als Eintrag beispielsweise in der Fußzeile der Nachricht verwendet haben könnten. Das Potential zur Bewertung R in den Ketten zu haben, führt zu Sicherheitsrisiken, so dass dies nicht mehr möglich ist. Stattdessen können wir uns einfach dafür entscheiden, glue::glue() oder paste() zu verwenden. Wenn ein Markdown- oder HTML-Element vorhanden ist, ist die Funktion md() erforderlich. Hier ist ein Beispiel für eine einfache Nachricht, die Markdown verwendet:\nemail \u0026lt;- compose_email( body = md( \u0026quot; ## Hello! This is an email message that was generated by the blastula package. Yep, we can use **Markdown** formatting but be sure to use the `md()` function. Here is a link to a great song ([E-MAIL ME!](https://youtu.be/-FcJbEg3vX8)). Cheers, The blastula team \u0026quot;), footer = md( \u0026quot; sent via the [blastula](https://rich-iannone.github.io/blastula) R package \u0026quot;) )  Wir können weiterhin eine Vorschau des E-Mail-Objekts im RStudio Viewer anzeigen, um die perfekte Komposition zu erhalten. Weitere Informationen zum Verfassen von E-Mails mit compose_email() finden Sie im Artikel Simple Email Composition auf der Projektwebsite.\nZum Versenden von E-Mails mit SMTP ist keine externe Software erforderlich In den wenigen Jahren, in denen blastula verfügbar war, stützte er sich zum Versenden von E-Mails auf verschiedene externe Software. Das stimmt nicht mehr. Wir erstellen jetzt einen RFC-2822-E-Mail-Body und senden E-Mails mit einer curl-Paketfunktion. Jetzt können E-Mails mit der Funktion smtp_send() zuverlässig auf allen wichtigen Computerplattformen ohne schwer zu installierende Abhängigkeiten gesendet werden.\nVerbesserte Berechtigungsnachweisverwaltung Das Paket verfügt jetzt über Funktionen zum Konfigurieren und Abrufen von Konfigurationsinformationen und SMTP-Anmeldeinformationen. Wir können dies mit create_smtp_creds_key() konfigurieren. Mit einem solchen hinzugefügten Schlüssel kann die creds_key()-Hilfe zum Versenden von E-Mails über smtp_send() verwendet werden. Alternativ kann eine Berechtigungsnachweisdatei mit der Funktion create_smtp_creds_file() erstellt werden (abgerufen mit creds_file()). Schließlich können die Anmeldeinformationen zum Zeitpunkt des Sendens mit der Funktion creds() vollständig angegeben werden. Immer wenn ein Passwort erforderlich ist, erscheint eine Aufforderung zur Eingabe des Passworts (der Passworttext wird ausgeblendet).\nEs gibt noch mehr! Andere Änderungen umfassen die automatische Bildintegration (über Base64-Codierung) durch die Verwendung der Funktionen add_image() und add_ggplot(), wenn sie mit compose_email() verwendet werden. Die Funktion add_imgur_image() erleichtert die Verwendung externer Bilder in E-Mails. Schließlich gibt es eine neue Reihe von block_*()-Funktionen, mit denen wir E-Mails mit komplexeren Layouts erstellen können.\nDie Zukunft ist da Ich hoffe aufrichtig, dass Sie die neue Version des blastula-Pakets testen. Mit R können wir so viele nützliche Dinge erschaffen. Die Möglichkeit, unsere Ergebnisse per E-Mail zu übermitteln, ist für den Absender und den Empfänger eine absolute Freude.\n  function openLang(evt, cityName) { var i, tabcontent, tablinks; tabcontent = document.getElementsByClassName(\"tabcontent\"); for (i = 0; i ","date":1574380800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574454660,"objectID":"4d81e889cbfec92d782654b9d919f230","permalink":"/post/blastula-0-3/","publishdate":"2019-11-22T00:00:00Z","relpermalink":"/post/blastula-0-3/","section":"post","summary":"The newest release of the **blastula** package lets you to do amazing things with HTML email in **R** and **RStudio Connect**.","tags":["R Packages"],"title":"blastula v0.3","type":"post"},{"authors":null,"categories":null,"content":" The book entitled Exploring Data with R teaches you how to do data analysis with R. The book doesn’t assume any prior experience with programming making it a great introduction with easy-to-follow examples and useful exercises.\n","date":1571529600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571529600,"objectID":"20281aed3cfbf9fa7fca750da29de323","permalink":"/projects/exploring-data-with-r-book/","publishdate":"2019-10-20T00:00:00Z","relpermalink":"/projects/exploring-data-with-r-book/","section":"projects","summary":"An introductory book for data analysis in R.","tags":["R Books"],"title":"[R book] Exploring Data with R","type":"projects"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":[],"categories":null,"content":"","date":1547683200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547683200,"objectID":"ea57c95009d46583f549e9ae1d8a340d","permalink":"/talk/rstudio-conf-2019/","publishdate":"2019-01-17T00:00:00Z","relpermalink":"/talk/rstudio-conf-2019/","section":"talk","summary":"A talk given at rstudio::conf 2019.","tags":[],"title":"Introducing the gt Package","type":"talk"},{"authors":null,"categories":null,"content":" With the gt package, anyone can make wonderful-looking tables using the R programming language. The gt philosophy: we can construct a wide variety of useful tables with a cohesive set of table parts. These include the table header, the stub, the stub head, the column labels, the table body, and the table footer.\nThe gt API is designed to be both straightforward yet powerful. The emphasis is on simple functions for the everyday display table needs. However, there are functions for customizing and annotating tables to convey additional information.\n","date":1521504000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1521504000,"objectID":"31b25af6531d4d0883a784f3dab5370a","permalink":"/projects/gt-pkg/","publishdate":"2018-03-20T00:00:00Z","relpermalink":"/projects/gt-pkg/","section":"projects","summary":"Easily generate information-rich, publication-quality tables from R","tags":["R Packages"],"title":"[R package] gt","type":"projects"},{"authors":null,"categories":null,"content":" The blastula package makes it easy to produce and send HTML email from R. The message can have three content areas (the body, the header, and the footer) and we can insert Markdown text, R expressions, block-based components, and even some raw HTML. The underlying HTML/CSS is meant to display properly across a wide range of email clients and webmail services. The resulting email message is responsive so it’ll look great on computers and mobile devices.\n","date":1502582400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502582400,"objectID":"37022a39ee9e857e037bbd8ad639a07d","permalink":"/projects/blastula-pkg/","publishdate":"2017-08-13T00:00:00Z","relpermalink":"/projects/blastula-pkg/","section":"projects","summary":"The blastula R package lets us send HTML email messages.","tags":["R Packages"],"title":"[R package] blastula","type":"projects"},{"authors":null,"categories":null,"content":" The pointblank package let’s us validate data in local data frames or tibbles, in CSV and TSV files, and in database tables (PostgreSQL and MySQL). We can get a detailed summary report of the interrogation, showing how many individual tests in each validation step had passed or failed. The self-contained HTML report provides detailed information on the validation outcomes and it can be used as web content.\n","date":1487808000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487808000,"objectID":"0c925a48661aa287e516b3344a71ecb8","permalink":"/projects/pointblank-pkg/","publishdate":"2017-02-23T00:00:00Z","relpermalink":"/projects/pointblank-pkg/","section":"projects","summary":"The pointblank R package lets us validate data tables.","tags":["R Packages"],"title":"[R package] pointblank","type":"projects"},{"authors":null,"categories":null,"content":" The DiagrammeR package has a collection of graph functions allow you to create graph objects, modify those graphs, get information from the graphs, and do many other useful things. We can easily generate network graphs with data available in tabular datasets. Two specialized data frames contain node data and attributes (node data frames) and edges with associated edge attributes (edge data frames). Because the attributes are always kept alongside the node and edge definitions (within the graph object itself), we can easily work with them.\n","date":1419724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1419724800,"objectID":"672d8104f5a9af8960efacc7c5dceeab","permalink":"/projects/diagrammer-pkg/","publishdate":"2014-12-28T00:00:00Z","relpermalink":"/projects/diagrammer-pkg/","section":"projects","summary":"The DiagrammeR R package lets create, modify, and visualize network graphs.","tags":["R Packages"],"title":"[R package] DiagrammeR","type":"projects"},{"authors":null,"categories":null,"content":" The stationaRy package allows for fast retrieval of meteorological data from met stations located all over the world. Weather data originates from the 29,729 stations available in this dataset where many of these contain data that go back decades. The data comes from the Integrated Surface Dataset (ISD), which is maintained by the National Oceanic and Atmospheric Administration (NOAA).\n","date":1397347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1397347200,"objectID":"ef1413ba0f65aca93e7de598e310527b","permalink":"/projects/stationary-pkg/","publishdate":"2014-04-13T00:00:00Z","relpermalink":"/projects/stationary-pkg/","section":"projects","summary":"The stationaRy R package gives us access to historical weather data.","tags":["R Packages"],"title":"[R package] stationaRy","type":"projects"},{"authors":null,"categories":null,"content":" splitr is an R package for conducting trajectory and dispersion modeling with HYSPLIT. This is useful for atmospheric scientists as the package helps to determine, from one or more receptor sites, where arriving air masses originated. Conversely, it’s possible to model trajectories of air masses from receptor sites. Forward and backward modeling of gas-phase or particulate matter can also be conducted from defined sites. It’s a means to help explain how, where, and when chemicals and materials are atmospherically transported, dispersed, and deposited.\n","date":1386633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1386633600,"objectID":"89abb0b75e9bc0996c37fc60dd5c46f9","permalink":"/projects/splitr-pkg/","publishdate":"2013-12-10T00:00:00Z","relpermalink":"/projects/splitr-pkg/","section":"projects","summary":"The splitr R package helps model wind trajectories and particle dispersion.","tags":["R Packages"],"title":"[R package] splitr","type":"projects"}]