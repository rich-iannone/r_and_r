[{"authors":["admin"],"categories":null,"content":" I’m a software engineer at RStudio. Most of my work involves creating R packages that make it easier to work with and communicate data. I also enjoy opportunities to teach people how to be successful with R.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"d33c1cd8bead9ce2a6229ddb7fdca4a5","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I’m a software engineer at RStudio. Most of my work involves creating R packages that make it easier to work with and communicate data. I also enjoy opportunities to teach people how to be successful with R.","tags":null,"title":"Richard Iannone","type":"authors"},{"authors":[],"categories":[],"content":"     English  French  German    The pointblank package is now at version 0.4 and is chock full of goodies. There are new functions that allow us to do really interesting things with data validation. Some of the existing functions gained new superpowers. The docs? Better than ever! They’ve been totally revised and there are plenty of easy-to-use examples too. You can install pointblank 0.4 from CRAN with:\ninstall.packages(\u0026quot;pointblank\u0026quot;) With the last iteration of pointblank the goal was to enable two important, yet quite distinct, data validation workflows using a common set of validation step functions. Let’s have another look at the rationale for those, which were:\ndata quality reporting pipeline-based data validation  For the first one, why is it so important? If you are dealing with data, and I’m sure you are, you really need to understand and get on top of data quality. Is the data good? Is it bad? What parts are good or bad? Are the bad parts really bad? Can we understand what’s making it bad? (I’m just assuming it’s bad.) Lots of questions, and we can get to answering them, so long as we have a process. What I’m hoping is that pointblank is up to the task.\nThe second workflow is also important, but it’s really different than the first. The idea is that you need to check your data before it proceeds further down a pipeline. Perhaps the input data (rigorously checked and cleaned, thanks to data quality reporting) is just fine, but, what about the transformed data in a pipeline? We ought to check that data too.\nThose are the main workflows but there are some new ways of using pointblank now.\nExpectation Functions There are now 24 expectation functions (e.g., expect_col_exists(), expect_rows_distinct(), expect_col_schema_match(), etc.) as complements to the 24 validation functions. All of these can be used for testthat tests of tabular data. These new functions have a simplified interface that exposes an easy-to-use failure threshold (defaulting to 1). We’ll go through some examples with the small_table dataset included in pointblank.\nsmall_table #\u0026gt; # A tibble: 13 x 8 #\u0026gt; date_time date a b c d e f #\u0026gt; \u0026lt;dttm\u0026gt; \u0026lt;date\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 2016-01-04 11:00:00 2016-01-04 2 1-bcd-345 3 3423. TRUE high #\u0026gt; 2 2016-01-04 00:32:00 2016-01-04 3 5-egh-163 8 10000. TRUE low #\u0026gt; 3 2016-01-05 13:32:00 2016-01-05 6 8-kdg-938 3 2343. TRUE high #\u0026gt; 4 2016-01-06 17:23:00 2016-01-06 2 5-jdo-903 NA 3892. FALSE mid #\u0026gt; 5 2016-01-09 12:36:00 2016-01-09 8 3-ldm-038 7 284. TRUE low #\u0026gt; 6 2016-01-11 06:15:00 2016-01-11 4 2-dhe-923 4 3291. TRUE mid #\u0026gt; 7 2016-01-15 18:46:00 2016-01-15 7 1-knw-093 3 843. TRUE high #\u0026gt; 8 2016-01-17 11:27:00 2016-01-17 4 5-boe-639 2 1036. FALSE low #\u0026gt; 9 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 10 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 11 2016-01-26 20:07:00 2016-01-26 4 2-dmx-010 7 834. TRUE low #\u0026gt; 12 2016-01-28 02:51:00 2016-01-28 2 7-dmx-010 8 108. FALSE low #\u0026gt; 13 2016-01-30 11:23:00 2016-01-30 1 3-dka-303 NA 2230. TRUE high  # With the `expect_*()` form, we would # typically perform one validation at a time # (the same way that testthat tests operate) expect_col_vals_between( small_table, vars(c), 1, 9, na_pass = TRUE ) This returns absolutely nothing, which means the test worked! In the case that it doesn’t work, we get an informative message:\nexpect_col_vals_between( small_table, vars(c), 23, 34, na_pass = TRUE ) Error: Exceedance of failed test units where values in `c` should have been between `23` and `34`. The `expect_col_vals_between()` validation failed beyond the absolute threshold level (1). * failure level (11) \u0026gt;= failure threshold (1)  By the way, these messages are consistent with the error and warning messages that are shown when using validation functions directly on data (e.g., small_table %\u0026gt;% col_vals_between(...)).\n Test Functions On top of the expect_*() set of functions, there are now 24 test functions (e.g., test_col_exists(), test_rows_distinct(), test_col_schema_match(), etc.) to further complement the 24 validation functions. These functions return a logical value: TRUE if the failure threshold (having a default of 1) is not exceeded, FALSE otherwise. These test_*() functions use the same simplified interface of the expect_*() functions.\n# With the `test_*()` form, we should get a # single logical value returned to us test_col_vals_between( small_table, vars(c), 1, 9, na_pass = TRUE ) [1] TRUE  col_vals_expr(), expect_col_vals_expr(), and test_col_vals_expr() For those times when you just want a DIY expression for your validation, the col_vals_expr() function (and the expectation and test variants) could be what you need. The dplyr expr(), case_when(), and between() functions are now re-exported in pointblank for easier accessibility here since they work exceedingly well with the new functions. Here’s an example:\n# Let\u0026#39;s use a tiny table for testing here tbl \u0026lt;- dplyr::tibble( a = c(1, 2, 1, 7, 8, 6), b = c(0, 0, 0, 1, 1, 1), c = c(0.5, 0.3, 0.8, 1.4, 1.9, 1.2), ) tbl #\u0026gt; # A tibble: 6 x 3 #\u0026gt; a b c #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 1 0 0.5 #\u0026gt; 2 2 0 0.3 #\u0026gt; 3 1 0 0.8 #\u0026gt; 4 7 1 1.4 #\u0026gt; 5 8 1 1.9 #\u0026gt; 6 6 1 1.2 # Test that values in column `a` # are integer-like by using the R modulo # operator and expecting `0` test_col_vals_expr(tbl, ~ a %% 1 == 0) [1] TRUE # We can do more complex things by # taking advantage of the `case_when()` # and `between()` functions (available # for use in the pointblank package) tbl %\u0026gt;% test_col_vals_expr(~ case_when( b == 0 ~ a %\u0026gt;% between(0, 5) \u0026amp; c \u0026lt; 1, b == 1 ~ a \u0026gt; 5 \u0026amp; c \u0026gt;= 1 )) [1] TRUE Should the evaluation of the expression not work out (for example, if the non-existent d column were to be used in the above example) you’ll get an NA value returned. If using an agent, the report will show that the evaluation was unsuccessful (look for the explosion in the EVAL column).\n New R Markdown Features Almost forgot about this one! A new R Markdown validation feature allows for validation testing within specialized validation code chunks where the validate = TRUE option is set. Using pointblank validation functions on data in these marked code chunks will flag overall failure if the stop threshold is exceeded anywhere. All errors are reported in the validation code chunk after rendering the document to HTML, where green or red status buttons indicate whether all validations succeeded or failures occurred. But, better to show than to explain, here’s an animation:\nThere’s a very useful R Markdown template for this new R Markdown validation feature: Pointblank Validation.\nUsing pointblank in an R Markdown workflow is enabled by default once the pointblank library is loaded. While the framework for such testing is set up by default, the new validate_rmd() function offers an opportunity to set UI and logging options.\n The agent Report The appearance of the agent report has improved (a lot!) and it’s gained some new features:\ndata extracts for failing rows (on row-based validation steps) can be downloaded as CSVs via the new buttons that appear in the EXT column there are useful tooltips on most fields of the table (e.g., hovering over items in STEP will show the ‘brief’, TBL icons will describe whether any preconditions were applied to the table prior to interrogation, etc.), and there are printing improvements in the COLUMNS and VALUES columns (e.g., table columns are distinguished from literal values).  Here’s a diagram that better explains the whole thing:\nThis bit of reporting is really important so expect even more improvements in an upcoming version.\n Scanning Your Data with scan_data(): Improvements! The scan_data() function let’s you ‘Thoroughly scan the table data so as to understand it better’ (that’s from the help page, at ?scan_data). In case you haven’t seen it, this function generates an HTML report that explains the input table data. It’s a great thing to use before calling up an agent to validate the data. With this function, we can now quickly get to understanding the data with some level of precision. The reporting output contains several sections to make everything more digestible, and these are:\nOverview: Table dimensions, duplicate row count, column types, and reproducibility information Variables: A summary for each table variable and further statistics and summaries depending on the variable type Interactions: A matrix plot that shows interactions between variables Correlations: A set of correlation matrix plots for numerical variables Missing Values: A summary figure that shows the degree of missingness across variables, and Sample: A table that provides the head and tail rows of the dataset  It’s pretty cool! Try it out with your favorite dataset. I created a few examples, in various languages even, in RPubs:\n    \nAll of those Table Scans are of the dplyr::storms dataset. But whaddabout database tables? That’s the improvement this time round! You can now use scan_data() to scan some DB tables. Here are two brand-new examples using the full_region table of the Rfam database (hosted publicly at “mysql-rfam-public.ebi.ac.uk”) and the assembly table of the Ensembl database (hosted publicly at “ensembldb.ensembl.org”).\n \n Nicer Lookin’ Email You can send HTML email with the agent report inside (thanks to some help by the blastula package). There’s seemingly no limit to the customizability of the message body, since the email_blast() function has full access to the agent intel (have a look at the help article at ?email_blast for all the details on this). However, sometimes you want a reasonably-nice default email that won’t take much work to develop. In this release, the default look of the email is much easier on the eyes.\nIt uses a small version of the agent report (575px wide) that still has those useful tooltips that provide briefs (an unfortunate name for the short descriptions of each validation step). Sure, you could customize the email yourself with the msg_header, msg_body, and msg_footer args but, now, you might not have a compulsion to do so.\n Wrapping Up I hope this gives some insight into what pointblank is all about and where its development is headed. Aside from these sizable improvements and new features, there were also plenty of bugfixes and smaller quality-of-life changes that made it into this release. As ever, I hope you get a chance to try it out on your own data.\n  Le package pointblank est maintenant à la version 0.4 et regorge de bonbons. Il y a de nouvelles fonctions qui nous permettent de faire des choses vraiment intéressantes avec la validation des données. Certaines des fonctions existantes ont acquis de nouvelles superpuissances. La documentation? Mieux que jamais! Ils ont été entièrement révisés et il existe également de nombreux exemples faciles à utiliser. Vous pouvez installer pointblank 0.4 de CRAN avec:\ninstall.packages(\u0026quot;pointblank\u0026quot;) Avec la dernière version de ** pointblank **, l’objectif était d’activer deux workflows de validation de données importants, mais assez distincts, à l’aide d’un ensemble commun de fonctions d’étape de validation. Jetons un autre regard sur la justification de ceux-ci, qui étaient:\nrapports sur la qualité des données validation des données basée sur le pipeline  Pourquoi le premier point est-il si important? Si vous traitez avec des données, et je suis sûr que vous l’êtes, vous devez vraiment comprendre et maîtriser la qualité des données. Les données sont-elles bonnes? Est-il mauvais? Quelles parties sont bonnes ou mauvaises? Les mauvaises parties sont-elles vraiment mauvaises? Pouvons-nous comprendre ce qui le rend mauvais? (Je suppose simplement que c’est mauvais.) Beaucoup de questions, et nous pouvons y répondre, tant que nous avons un processus. Ce que j’espère, c’est que pointblank est assez bon pour tout cela.\nLe deuxième flux de travail est également important, mais il est vraiment différent du premier. Vous devez vérifier vos données avant de poursuivre leur progression dans un pipeline. Peut-être que les données d’entrée (rigoureusement vérifiées et nettoyées, grâce aux rapports sur la qualité des données) sont très bien, mais qu’en est-il des données transformées dans un pipeline? Allons! Il faut le vérifier et vous le savez! Vous pourriez avoir de graves problèmes si vous ignorez tout cela. Alors faites-le! Simplement fais-le!\nQuoi qu’il en soit, ce sont les principaux workflows. Il y a de nouvelles choses qui permettent de nouvelles façons d’utiliser pointblank. C’est assez excitant!\nExpectation fonctions Il existe désormais 24 fonctions expectation (par exemple, expect_col_exists(), expect_rows_distinct(), expect_col_schema_match(), etc.) en complément des 24 fonctions de validation. Tous ces éléments peuvent être utilisés pour testthat tests de données tabulaires avec une interface simplifiée qui expose un seuil de défaillance facile à utiliser (par défaut à 1). Explorons cela à travers des exemples. Nous utiliserons l’ensemble de données small_table inclus dans pointblank.\nsmall_table #\u0026gt; # A tibble: 13 x 8 #\u0026gt; date_time date a b c d e f #\u0026gt; \u0026lt;dttm\u0026gt; \u0026lt;date\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 2016-01-04 11:00:00 2016-01-04 2 1-bcd-345 3 3423. TRUE high #\u0026gt; 2 2016-01-04 00:32:00 2016-01-04 3 5-egh-163 8 10000. TRUE low #\u0026gt; 3 2016-01-05 13:32:00 2016-01-05 6 8-kdg-938 3 2343. TRUE high #\u0026gt; 4 2016-01-06 17:23:00 2016-01-06 2 5-jdo-903 NA 3892. FALSE mid #\u0026gt; 5 2016-01-09 12:36:00 2016-01-09 8 3-ldm-038 7 284. TRUE low #\u0026gt; 6 2016-01-11 06:15:00 2016-01-11 4 2-dhe-923 4 3291. TRUE mid #\u0026gt; 7 2016-01-15 18:46:00 2016-01-15 7 1-knw-093 3 843. TRUE high #\u0026gt; 8 2016-01-17 11:27:00 2016-01-17 4 5-boe-639 2 1036. FALSE low #\u0026gt; 9 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 10 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 11 2016-01-26 20:07:00 2016-01-26 4 2-dmx-010 7 834. TRUE low #\u0026gt; 12 2016-01-28 02:51:00 2016-01-28 2 7-dmx-010 8 108. FALSE low #\u0026gt; 13 2016-01-30 11:23:00 2016-01-30 1 3-dka-303 NA 2230. TRUE high  # Avec le formulaire `expect_*()`, nous # effectue généralement une validation à la fois # (de la même manière que les tests fonctionnent) expect_col_vals_between( small_table, vars(c), 1, 9, na_pass = TRUE ) Cela ne renvoie rien. Rien du tout. C’est bien! Cela signifie que le test a fonctionné! Dans le cas où cela ne fonctionne pas, nous obtenons un message informatif:\nexpect_col_vals_between( small_table, vars(c), 23, 34, na_pass = TRUE ) Error: Exceedance of failed test units where values in `c` should have been between `23` and `34`. The `expect_col_vals_between()` validation failed beyond the absolute threshold level (1). * failure level (11) \u0026gt;= failure threshold (1)  Ces messages sont cohérents avec les messages d’erreur et d’avertissement qui s’affichent lors de l’utilisation de fonctions de validation directement sur les données (par exemple, small_table %\u0026gt;% col_vals_between (...)).\n Test fonctions En plus de l’ensemble de fonctions expect_*(), il existe désormais 24 fonctions test (par exemple, test_col_exists(), test_rows_distinct(), test_col_schema_match(), etc.) pour compléter 24 fonctions de validation. Ces fonctions renvoient une valeur logique: TRUE si le seuil de défaillance (ayant une valeur par défaut de 1) n’est pas dépassé, FALSE sinon. Ces fonctions test_*() utilisent la même interface simplifiée que les fonctions expect_*().\n# Avec le formulaire `test_*()`, nous # devrions obtenir un valeur TRUE ou FALSE # unique qui nous est retournée test_col_vals_between( small_table, vars(c), 1, 9, na_pass = TRUE ) [1] TRUE  col_vals_expr(), expect_col_vals_expr() et test_col_vals_expr() Si vous voulez juste une expression simple pour votre validation, la fonction col_vals_expr() (et les variantes expectation et test) pourrait être ce dont vous avez besoin. Les fonctions dplyr expr(), case_when() et between() sont maintenant réexportées dans pointblank pour une accessibilité plus facile ici. Ils fonctionnent à merveille avec les nouvelles fonctions. Voici un exemple:\n# Utilisons une p\u0026#39;tit table pour tester tbl \u0026lt;- dplyr::tibble( a = c(1, 2, 1, 7, 8, 6), b = c(0, 0, 0, 1, 1, 1), c = c(0.5, 0.3, 0.8, 1.4, 1.9, 1.2), ) tbl #\u0026gt; # A tibble: 6 x 3 #\u0026gt; a b c #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 1 0 0.5 #\u0026gt; 2 2 0 0.3 #\u0026gt; 3 1 0 0.8 #\u0026gt; 4 7 1 1.4 #\u0026gt; 5 8 1 1.9 #\u0026gt; 6 6 1 1.2 # Testez les valeurs de la colonne `a` # sont de type entier en utilisant le # module R opérateur et attend `0` test_col_vals_expr(tbl, ~ a %% 1 == 0) [1] TRUE # Nous pouvons faire des choses plus # complexes en profitant du `case_when()` # et `between()` fonctions (disponibles # à utiliser dans le package pointblank) tbl %\u0026gt;% test_col_vals_expr(~ case_when( b == 0 ~ a %\u0026gt;% between(0, 5) \u0026amp; c \u0026lt; 1, b == 1 ~ a \u0026gt; 5 \u0026amp; c \u0026gt;= 1 )) [1] TRUE Si l’évaluation de l’expression ne fonctionne pas (par exemple, la colonne d inexistante a été utilisée ci-dessus), vous obtiendrez une valeur NA. Si vous utilisez un agent, le rapport montrera que l’évaluation a échoué (recherchez l’explosion dans la colonne EVAL). C’est la bombe!\n Nouvelles fonctionnalités R Markdown Une nouvelle fonctionnalité de validation R Markdown permet d’effectuer des tests de validation dans des blocs de code de validation spécialisés où l’option validate = TRUE est définie. Voici une animation qui montre comment cela fonctionne:\nIl existe un nouveau template R Markdown pour cela, appelé «Pointblank Validation».\nL’utilisation de pointblank dans un workflow R Markdown est activée par défaut une fois pointblank chargée. La nouvelle fonction validate_rmd() offre la possibilité de définir des options de journalisation.\n Le rapport d’agent L’apparence du rapport d’agent est désormais bien meilleure. Il a gagné de nouvelles fonctionnalités:\nles extraits de données pour les lignes défaillantes (lors des étapes de validation basées sur les lignes) peuvent être téléchargés au format CSV via les nouveaux boutons qui apparaissent dans la colonne EXT il existe des info-bulles utiles sur la plupart des champs du tableau (par exemple, survoler les éléments dans STEP affichera le résumé, les icônes TBL décriront si des conditions préalables ont été appliquées au tableau avant l’interrogation, etc.), et il y a des améliorations d’impression dans les colonnes COLUMNS et VALUES (par exemple, les colonnes du tableau sont distinguées des valeurs littérales).  Voici un diagramme utile:\nCe rapport est super important. Attendez-vous à d’autres améliorations dans un avenir proche.\n Améliorations avec scan_data() Au cas où vous ne l’auriez pas vu, cette fonction génère un rapport HTML qui parcourt les données de la table d’entrée. C’est une bonne chose à utiliser avant d’appeler un agent pour valider les données. Avec cette fonction, nous pouvons maintenant rapidement comprendre les données avec un certain niveau de précision. La sortie du rapport contient plusieurs sections pour rendre tout plus digestible, et ce sont:\nAperçu: dimensions de la table, nombre de lignes en double, types de colonnes et informations de reproductibilité Variables: un résumé pour chaque variable du tableau et d’autres statistiques et résumés selon le type de variable Interactions: un graphique matriciel qui montre les interactions entre les variables Corrélations: un ensemble de graphiques matriciels de corrélation pour les variables numériques Valeurs manquantes: une figure récapitulative qui montre le degré de disparité entre les variables, et Exemple: un tableau qui fournit les lignes de tête et de queue de l’ensemble de données  C’est bon! Essayez-le avec votre jeu de données préféré. J’ai créé quelques exemples, dans différentes langues même, dans RPubs:\n    \nTous ces éléments font partie de l’ensemble de données dplyr::storms. Mais à propos des tables de base de données? C’est l’amélioration cette fois-ci! Vous pouvez maintenant utiliser scan_data() pour analyser certaines tables de base de données. Voici deux nouveaux exemples utilisant la table full_region de la base de données Rfam (hébergée publiquement sur “mysql-rfam-public.ebi.ac.uk”) et la table assembly de Ensembl base de données (hébergée publiquement sur “ensembldb.ensembl.org”).\n \n Courriel: J’aime le way qu’à hang Vous pouvez envoyer un e-mail HTML avec le rapport de l’agent à l’intérieur (grâce à l’aide du package blastula). Il n’y a apparemment aucune limite à la personnalisation du corps du message, car la fonction email_blast() a un accès complet aux informations de l’agent (consultez l’article d’aide à ?email_blast pour tous les détails à ce sujet). Cependant, parfois, vous voulez un e-mail par défaut assez agréable qui ne prendra pas beaucoup de travail à envoyer. Dans cette version, l’apparence par défaut de l’e-mail est beaucoup plus facile pour les yeux.\nIl utilise une petite version du rapport d’agent (575 px de large) qui a toujours des info-bulles qui fournissent des briefs (un nom malheureux en anglais pour les courtes descriptions de chaque étape de validation). Bien sûr, vous pouvez personnaliser l’e-mail avec les arguments msg_header, msg_body et msg_footer mais, maintenant, vous n’avez peut-être pas la contrainte de le faire.\n Conclusion J’espère que cela vous donnera un aperçu de ce qu’est pointblank et de son évolution. Mis à part ces améliorations considérables et ces nouvelles fonctionnalités, de nombreuses corrections de bugs et de petits changements de qualité de vie ont également été intégrés à cette version. Comme toujours, j’espère que vous aurez l’occasion de l’essayer sur vos propres données.\n  Das pointblank-Paket ist jetzt in Version 0.4 und voller Goodies. Es gibt neue Funktionen, mit denen wir wirklich interessante Dinge mit der Datenvalidierung tun können. Einige der bestehenden Funktionen erhielten neue Superkräfte. Die Dokumentation? Besser denn je! Sie wurden komplett überarbeitet und es gibt auch viele benutzerfreundliche Beispiele. Sie können pointblank 0.4 von CRAN installieren mit:\ninstall.packages(\u0026quot;pointblank\u0026quot;) Mit der letzten Version von pointblank bestand das Ziel darin, zwei wichtige, jedoch recht unterschiedliche Datenvalidierungs-Workflows mithilfe eines gemeinsamen Satzes von Validierungsschrittfunktionen zu ermöglichen. Lassen Sie uns noch einen Blick auf die Gründe für diejenigen werfen, die waren:\nBerichterstattung zur Datenqualität Pipeline-basierte Datenvalidierung2. pipeline-based data validation  Warum ist es für den ersten so wichtig? Wenn Sie mit Daten zu tun haben und ich bin sicher, dass Sie es sind, müssen Sie die Datenqualität wirklich verstehen und auf den neuesten Stand bringen. Sind die Daten gut? Ist es schlimm? Welche Teile sind gut oder schlecht? Sind die schlechten Teile wirklich schlecht? Können wir verstehen, was es schlecht macht? (Ich gehe nur davon aus, dass es schlecht ist.) Viele Fragen, und wir können sie beantworten, solange wir einen Prozess haben. Was ich hoffe ist, dass pointblank der Aufgabe gewachsen ist.\nDer zweite Workflow ist ebenfalls wichtig, unterscheidet sich jedoch erheblich vom ersten. Die Idee ist, dass Sie Ihre Daten überprüfen müssen, bevor sie weiter unten in einer Pipeline fortgesetzt werden. Vielleicht sind die Eingabedaten (dank Datenqualitätsberichterstattung streng geprüft und bereinigt) in Ordnung, aber was ist mit den transformierten Daten in einer Pipeline? Wir sollten auch diese Daten überprüfen.\nDies sind die Hauptworkflows, aber es gibt jetzt einige neue Möglichkeiten, pointblank zu verwenden.\nExpectation Funktionen Es gibt jetzt 24 Expectation-Funktionen (z. B. expect_col_exists(), expect_rows_distinct(), expect_col_schema_match() usw.) als Ergänzungen der 24 Validierungsfunktionen. All dies kann für testthat Testen von Tabellendaten mit einer vereinfachten Oberfläche verwendet werden, die einen benutzerfreundlichen Fehlerschwellenwert (standardmäßig 1) anzeigt. Wir werden einige Beispiele mit dem in pointblank enthaltenen small_table-Dataset durchgehen.\nsmall_table #\u0026gt; # A tibble: 13 x 8 #\u0026gt; date_time date a b c d e f #\u0026gt; \u0026lt;dttm\u0026gt; \u0026lt;date\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 2016-01-04 11:00:00 2016-01-04 2 1-bcd-345 3 3423. TRUE high #\u0026gt; 2 2016-01-04 00:32:00 2016-01-04 3 5-egh-163 8 10000. TRUE low #\u0026gt; 3 2016-01-05 13:32:00 2016-01-05 6 8-kdg-938 3 2343. TRUE high #\u0026gt; 4 2016-01-06 17:23:00 2016-01-06 2 5-jdo-903 NA 3892. FALSE mid #\u0026gt; 5 2016-01-09 12:36:00 2016-01-09 8 3-ldm-038 7 284. TRUE low #\u0026gt; 6 2016-01-11 06:15:00 2016-01-11 4 2-dhe-923 4 3291. TRUE mid #\u0026gt; 7 2016-01-15 18:46:00 2016-01-15 7 1-knw-093 3 843. TRUE high #\u0026gt; 8 2016-01-17 11:27:00 2016-01-17 4 5-boe-639 2 1036. FALSE low #\u0026gt; 9 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 10 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 11 2016-01-26 20:07:00 2016-01-26 4 2-dmx-010 7 834. TRUE low #\u0026gt; 12 2016-01-28 02:51:00 2016-01-28 2 7-dmx-010 8 108. FALSE low #\u0026gt; 13 2016-01-30 11:23:00 2016-01-30 1 3-dka-303 NA 2230. TRUE high  # Mit dem Formular `expect_*()` würden # wir Führen Sie normalerweise jeweils # eine Validierung durch (genauso wie # testthat Tests funktionieren) expect_col_vals_between( small_table, vars(c), 1, 9, na_pass = TRUE ) Dies gibt absolut nichts zurück: eine Leere. Dies bedeutet, dass der Test funktioniert hat. Falls es nicht funktioniert, erhalten wir eine informative Nachricht:\nexpect_col_vals_between( small_table, vars(c), 23, 34, na_pass = TRUE ) Error: Exceedance of failed test units where values in `c` should have been between `23` and `34`. The `expect_col_vals_between()` validation failed beyond the absolute threshold level (1). * failure level (11) \u0026gt;= failure threshold (1)  Übrigens stimmen diese Meldungen mit den Fehler- und Warnmeldungen überein, die angezeigt werden, wenn Validierungsfunktionen direkt für Daten verwendet werden (z. B. small_table %\u0026gt;% col_vals_between(...)).\n Test Funktionen Abgesehen von dem Funktionssatz expect_*() gibt es jetzt 24 test-Funktionen (z. B. test_col_exists(), test_rows_distinct(), test_col_schema_match() usw.), um die 24 weiter zu ergänzen Validierungsfunktionen. Diese Funktionen geben einen logischen Wert zurück: TRUE, wenn der Fehlerschwellenwert (mit einem Standardwert von 1) nicht überschritten wird, andernfalls FALSE. Diese test_*() Funktionen verwenden dieselbe vereinfachte Schnittstelle wie die expect_*() Funktionen.\n# Mit dem Formular `test_*()` sollten wir einen # einzelnen TRUE- oder FALSE-Wert erhalten, der # an uns zurückgegeben wird test_col_vals_between( small_table, vars(c), 1, 9, na_pass = TRUE ) [1] TRUE  col_vals_expr(), expect_col_vals_expr(), und test_col_vals_expr() Wenn Sie für Ihre Validierung einen einfachen Ausdruck benötigen, könnte die Funktion col_vals_expr() (und die Varianten expectation und test) genau das sein, was Sie benötigen. Die Funktionen dplyr expr(), case_when() und between() werden jetzt in pointblank erneut exportiert, um den Zugriff hier zu erleichtern, da sie mit den neuen Funktionen außerordentlich gut funktionieren. Hier ist ein Beispiel:\n# Lassen Sie uns hier eine winzige Tabelle # zum Testen verwenden tbl \u0026lt;- dplyr::tibble( a = c(1, 2, 1, 7, 8, 6), b = c(0, 0, 0, 1, 1, 1), c = c(0.5, 0.3, 0.8, 1.4, 1.9, 1.2), ) tbl #\u0026gt; # A tibble: 6 x 3 #\u0026gt; a b c #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 1 0 0.5 #\u0026gt; 2 2 0 0.3 #\u0026gt; 3 1 0 0.8 #\u0026gt; 4 7 1 1.4 #\u0026gt; 5 8 1 1.9 #\u0026gt; 6 6 1 1.2 # Testen Sie, ob die Werte in Spalte `a` # ganzzahlig sind, indem Sie den # R-Modulo-Operator verwenden und `0` erwarten test_col_vals_expr(tbl, ~ a %% 1 == 0) [1] TRUE # Wir können komplexere Dinge tun, indem # wir die Funktionen `case_when()` und # `between()` nutzen (verfügbar für die # Verwendung im pointblank-Paket). tbl %\u0026gt;% test_col_vals_expr(~ case_when( b == 0 ~ a %\u0026gt;% between(0, 5) \u0026amp; c \u0026lt; 1, b == 1 ~ a \u0026gt; 5 \u0026amp; c \u0026gt;= 1 )) [1] TRUE Sollte die Auswertung des Ausdrucks nicht funktionieren (z. B. wurde oben die nicht vorhandene Spalte d verwendet), wird ein NA-Wert zurückgegeben. Wenn Sie einen Agenten verwenden, zeigt der Bericht, dass die Auswertung nicht erfolgreich war (suchen Sie nach der Explosion in der Spalte EVAL).\n Neue R Markdown Funktionen Eine neue R Markdown-Validierungsfunktion ermöglicht Validierungstests in speziellen Validierungscode-Blöcken, in denen die Option validate = TRUE festgelegt ist. Die Verwendung von Pointblank-Validierungsfunktionen für Daten in diesen Codeblöcken zeigt einen Gesamtfehler an, wenn der Stoppschwellenwert irgendwo überschritten wird. Alle Fehler werden im Validierungscode-Block gemeldet, nachdem das Dokument in HTML gerendert wurde. Hier ist eine Animation:\nHierfür gibt es eine neue R-Markdown-template namens “Pointblank Validation”.\nDie Verwendung von pointblank in einem R Markdown-Workflow ist standardmäßig aktiviert, sobald die pointblank-Bibliothek geladen ist. Während das Framework für solche Tests standardmäßig eingerichtet ist, bietet die neue Funktion validate_rmd() die Möglichkeit, Benutzeroberflächen- und Protokollierungsoptionen festzulegen.\n Der agent Bericht Das Erscheinungsbild des Agentenberichts wurde erheblich verbessert und verfügt nun über einige neue Funktionen:\nDatenextrakte für fehlerhafte Zeilen (in zeilenbasierten Validierungsschritten) können über die neuen Schaltflächen in der Spalte EXT als CSVs heruntergeladen werden In den meisten Feldern der Tabelle gibt es nützliche QuickInfos (z. B. wenn Sie den Mauszeiger über Elemente in STEP halten, wird die Kurzdarstellung angezeigt, TBL-Symbole beschreiben, ob vor der Abfrage Vorbedingungen auf die Tabelle angewendet wurden usw.) Es gibt Druckverbesserungen in den Spalten COLUMNS und VALUES (z. B. werden Tabellenspalten von Literalwerten unterschieden).  Hier ist ein Diagramm:\nDas ist alles sehr wichtig. Erwarten Sie weitere Verbesserungen in einer kommenden Version.\n Verbesserungen an der Funktion scan_data() Diese Funktion scan_data() generiert einen HTML-Bericht, in dem die Daten der Eingabetabelle erläutert werden. Es ist gut zu verwenden, bevor Sie die Daten validieren. Mit dieser Funktion können wir die Daten jetzt schnell und präzise verstehen. Die Berichtsausgabe enthält mehrere Abschnitte, um alles besser verdaulich zu machen. Diese sind:\nÜbersicht: Tabellenabmessungen, doppelte Zeilenanzahl, Spaltentypen und Informationen zur Reproduzierbarkeit Variablen: Eine Zusammenfassung für jede Tabellenvariable sowie weitere Statistiken und Zusammenfassungen je nach Variablentyp Interaktionen: Ein Matrixdiagramm, das Interaktionen zwischen Variablen zeigt Korrelationen: Eine Reihe von Korrelationsmatrixdiagrammen für numerische Variablen Fehlende Werte: Eine zusammenfassende Abbildung, die den Grad des Fehlens zwischen Variablen und zeigt Beispiel: Eine Tabelle, die die Kopf- und Endzeilen des Datensatzes enthält  Es ist prima. Probieren Sie es mit Ihrem Lieblingsdatensatz aus. Ich habe einige Beispiele in verschiedenen Sprachen in RPubs erstellt:\n    \nAlle diese Beispiele verwenden den Datensatz dplyr::storms. Datenbanktabellen? Das ist die neue Verbesserung. Sie können jetzt scan_data() für Datenbanktabellen verwenden. Hier sind zwei neue Beispiele, die die Tabelle full_region der Rfam-Datenbank (öffentlich gehostet unter “mysql-rfam-public.ebi.ac.uk”) und die assembly-Tabelle des Ensembl verwenden. Datenbank (öffentlich gehostet unter “ensembldb.ensembl.org”).\n \n Besseres Erscheinungsbild für E-Mail Sie können eine HTML-E-Mail mit dem Bericht des Agenten senden. Dies wird durch das blastula-Paket unterstützt. Der Anpassbarkeit des Nachrichtentexts sind keine wirklichen Grenzen gesetzt, da die Funktion email_blast() nach der Abfrage vollen Zugriff auf Informationen hat. Weitere Informationen finden Sie im Hilfeartikel unter ?email_blast. Manchmal möchten Sie jedoch eine gute Standard-E-Mail, deren Erstellung nicht viel Arbeit erfordert. In dieser Version sieht das Standard-Erscheinungsbild der E-Mail viel besser aus.\nHierbei wird eine kleine Version des Agentenberichts (575 Pixel breit) verwendet, die noch QuickInfos enthält, die briefs enthalten (ein schlecht gewählter englischer Name für die Kurzbeschreibungen der einzelnen Validierungsschritte). Sie können die E-Mail selbst mit den Argumenten msg_header, msg_body und msg_footer anpassen. Möglicherweise möchten Sie dies jetzt jedoch nicht tun.\n Abschließend Ich hoffe, dies gibt einen Einblick in das, worum es bei pointblank geht und wohin seine Entwicklung geht. Abgesehen von diesen beträchtlichen Verbesserungen und neuen Funktionen gab es auch viele Bugfixes und kleinere Änderungen. Ich hoffe, Sie haben die Möglichkeit, es an Ihren eigenen Daten auszuprobieren.\n   function openLang(evt, cityName) { var i, tabcontent, tablinks; tabcontent = document.getElementsByClassName(\"tabcontent\"); for (i = 0; i ","date":1592956800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593022200,"objectID":"3ec29e562c4f301725e1b86ca20712e8","permalink":"/post/pointblank-0-4/","publishdate":"2020-06-24T00:00:00Z","relpermalink":"/post/pointblank-0-4/","section":"post","summary":"The **pointblank** package at v0.4 has a whole lot more functions than ever before. And, the existing functions have been *improved*!","tags":["R Packages"],"title":"pointblank v0.4","type":"post"},{"authors":[],"categories":[],"content":"    English  French  German    The newest release of the pointblank package makes it really easy to validate your data with workflows attuned to your data quality needs. You can install pointblank 0.3 from CRAN with:\ninstall.packages(\u0026quot;pointblank\u0026quot;) The design goals of pointblank are to enable two important data validation workflows with a common set of validation step functions, and, to have the code work seamlessly with data in local data tables and with database tables.\nThe two dominant workflows that pointblank enables are:\ndata quality reporting pipeline-based data validation  The first workflow is concerned with the data quality of the target table. One would use validation step functions to create a validation plan. That plan results in an interrogation of the table data. Finally, we get a report of the interrogation to ascertain data quality. The key is to use a large number of validation step functions to reveal inconsistencies or errors in the table.\nThe second workflow is useful in a data-transformation pipeline that uses tabular data. The validation functions are used directly with data to either warn us of unforeseen data integrity problems or to completely stop the pipeline. Stopping is a good idea when dependent, downstream processes (that would use the data to some extent) would be compromised by bad data. Both workflows use a common set of validation step functions, ‘action levels’ (i.e., failure thresholds) can be set in a stepwise manner. Additionally, we can choose to use our own R functions to create side effects like logging.\nBoth workflows make use of a large collection of simple validation step functions. These functions are named such that it’s obvious what the validation does. For example, the col_vals_gt() function tests whether cell values in a column are greater than a specified value. The interface for each step function is consistent but also optimized for the particular operation.\nA Walkthrough of pointblank in the Data Quality Reporting Workflow To determine the level of data quality for a table we use something called an agent. It develops a validation plan, performs the interrogation, and holds information about that interrogation (we would then ask for a report). The create_agent() function is used to create the agent. The target table is given to the agent and the table can be a tibble or a tbl_dbi object that’s made through a database connection and the dplyr::tbl() function.\nWe use validation step functions to build a validation plan. There are 23 of them and some check for the existence or the type of column (col_exists() or the group of col_is_*() functions) whereas others perform a check in each table cell within a column (e.g., all of the col_vals_*() functions). We apply our own understanding of the data in the target table when using the pointblank step functions, and, we use as many as is necessary for adequate testing.\nAfter using validation step functions to create a validation plan, the interrogate() function should then be used. With that, the table will be interrogated and the necessary validation information will be stored in the agent.\nThe pointblank package contains a dataset called small_table which is indeed small but ideal for simple examples:\nsmall_table #\u0026gt; # A tibble: 13 x 8 #\u0026gt; date_time date a b c d e f #\u0026gt; \u0026lt;dttm\u0026gt; \u0026lt;date\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 2016-01-04 11:00:00 2016-01-04 2 1-bcd-345 3 3423. TRUE high #\u0026gt; 2 2016-01-04 00:32:00 2016-01-04 3 5-egh-163 8 10000. TRUE low #\u0026gt; 3 2016-01-05 13:32:00 2016-01-05 6 8-kdg-938 3 2343. TRUE high #\u0026gt; 4 2016-01-06 17:23:00 2016-01-06 2 5-jdo-903 NA 3892. FALSE mid #\u0026gt; 5 2016-01-09 12:36:00 2016-01-09 8 3-ldm-038 7 284. TRUE low #\u0026gt; 6 2016-01-11 06:15:00 2016-01-11 4 2-dhe-923 4 3291. TRUE mid #\u0026gt; 7 2016-01-15 18:46:00 2016-01-15 7 1-knw-093 3 843. TRUE high #\u0026gt; 8 2016-01-17 11:27:00 2016-01-17 4 5-boe-639 2 1036. FALSE low #\u0026gt; 9 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 10 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 11 2016-01-26 20:07:00 2016-01-26 4 2-dmx-010 7 834. TRUE low #\u0026gt; 12 2016-01-28 02:51:00 2016-01-28 2 7-dmx-010 8 108. FALSE low #\u0026gt; 13 2016-01-30 11:23:00 2016-01-30 1 3-dka-303 NA 2230. TRUE high  The validation plan for this table uses the following assertions:\nthe date_time column is a POSIXct date-time column column f contains only the values \"low\", \"mid\", and \"high\" the values in column a are all less than 10 The strings in column b conform to a specified regex pattern column d has values in the range of 0 to 5000 (this is not entirely true!)  Here is the code for the above validation logic:\nagent \u0026lt;- small_table %\u0026gt;% create_agent() %\u0026gt;% col_is_posix(vars(date_time)) %\u0026gt;% col_vals_in_set(vars(f), set = c(\u0026quot;low\u0026quot;, \u0026quot;mid\u0026quot;, \u0026quot;high\u0026quot;)) %\u0026gt;% col_vals_lt(vars(a), value = 10) %\u0026gt;% col_vals_regex(vars(b), regex = \u0026quot;^[0-9]-[a-z]{3}-[0-9]{3}$\u0026quot;) %\u0026gt;% col_vals_between(vars(d), left = 0, right = 5000) %\u0026gt;% interrogate() The agent object gives us a little bit of information about how the interrogation went:\nagent #\u0026gt; pointblank agent // \u0026lt;agent_2020-01-13_04:14:09\u0026gt; #\u0026gt; #\u0026gt; number of validation steps: 5 #\u0026gt; #\u0026gt; interrogation (2020-01-13 04:14:09) resulted in: #\u0026gt; - 4 passing validations #\u0026gt; - 1 failing validation more info: `get_agent_report()` The 4 passing validations means that all of the individual validations in four validation steps passed without any errors. One validation step failed with at least one test unit failing (each cell tested is equivalent to 1 test unit). We can generate a report with more detail by using get_agent_report():\nget_agent_report(agent) The report is a gt table, which is printed by default if we have the gt package installed (use remotes::install_github(\"rstudio/gt\") to install that package). The first five columns of the report are recognizable since they are names of the validation step functions and their parameters. The preconditions? column indicates whether the table was altered just before interrogation (for that validation step). The Units column shows us the total number of test units for each validation step. The n_pass column gives the number of passing test units while the f_pass column indicates the fraction of passing test units. The W, S, N indicators tell us whether we have entered either of the WARN, STOP, or NOTIFY states for these validation steps. Because we didn’t set any threshold levels for these states, they are irrelevant for this report. Finally, the Extract indicator tells us whether there are data extracts available for failed test units. For step 5, the col_vals_between() validation step, there is a data extract available. We can have a look at that extract with get_data_extracts():\nget_data_extracts(agent, i = 5) #\u0026gt; # A tibble: 1 x 8 #\u0026gt; date_time date a b c d e f #\u0026gt; \u0026lt;dttm\u0026gt; \u0026lt;date\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 2016-01-04 00:32:00 2016-01-04 3 5-egh-163 8 10000. TRUE low Recall that validation step 5 asserted that all values in column d should be between 0 and 5000, however, this extract of small_table shows that column d has a value that lies outside this specified range.\nA Walkthrough of pointblank in the Pipeline-based Data Validation Workflow The second workflow, pipeline-based data validations, somewhat simplifies the process for checking data directly. There is no agent involved here and we instead call validation step functions directly on the data table objects. Because there isn’t an agent, there won’t be a report either. The idea is that the side effects are most important here (the data will pass through the validation functions unchanged). We can trigger warnings, raise errors, or write out logs when exceeding specified failure thresholds.\nWhere would we do this? When importing data we could test that data by passing it through a few validation step functions with warn_at and stop_at threshold levels set. If we were to transform a data table, we could likewise use a set of validation step functions as a QA/QC measure. If bad data quality might be bad for a downstream data product, it’s probably better to stop the process through pointblank validation tests and then do root-cause analysis to fix the data quality problem.\nLet’s use the statements from the previous example to work within the pipeline-based data validation workflow. In this case, we’ll use a simple call of the action_levels() function to generate the al object. It’s passed to the actions argument of every validaton step function. The setting implies that the pipeline will be stopped when there is a single test unit failure (with stop_at = 1).\n# Create an `action_levels` object, stopping the pipeline # if we get a single failing test unit al \u0026lt;- action_levels(stop_at = 1) small_table %\u0026gt;% col_is_posix(vars(date_time), actions = al) %\u0026gt;% col_vals_in_set(vars(f), set = c(\u0026quot;low\u0026quot;, \u0026quot;mid\u0026quot;, \u0026quot;high\u0026quot;), actions = al) %\u0026gt;% col_vals_lt(vars(a), value = 10, actions = al) %\u0026gt;% col_vals_regex(vars(b), regex = \u0026quot;^[0-9]-[a-z]{3}-[0-9]{3}$\u0026quot;, actions = al) %\u0026gt;% col_vals_between(vars(d), left = 0, right = 5000, actions = al) Error: The validation (`col_vals_between()`) meets or exceeds the stop threshold This is one of those times when we might be glad to see an error. The threshold setting stopped the evaluation of the pipeline and, in turn, stops the running script if it’s deployed and automatically running on the regular. The action_levels() function is quite powerful and it allows us to define custom functions that are evaluated when entering each of the three failure states. In this type of workflow we don’t need to define those functions, pointblank will automatically do the sensible thing and provide a stock warning() or stop() message.\nWrapping Up These short demonstrations show the main features of the two data validation workflows of pointblank. There are many things you can do to precisely define the validation steps and to cause the correct action to occur when entering different failure states. I hope you’re inclined to try it out on your own data!\n La dernière version du package pointblank facilite la validation de vos données avec des workflows adaptés à vos besoins en matière de qualité des données. Vous pouvez installer pointblank 0.3 avec:\ninstall.packages(\u0026quot;pointblank\u0026quot;) L’objectif de conception de pointblank est de permettre deux workflows de validation de données importants avec un ensemble commun de fonctions d’étape de validation et le code écrit devrait fonctionner de manière transparente avec les données des tables de données locales et avec les données des bases de données.\nLes deux workflows dominants que permet pointblank sont:\nrapports sur la qualité des données validations de données basées sur le pipeline  Le premier workflow concerne la qualité des données de la table cible. On utiliserait des fonctions d’étape de validation pour créer un plan de validation. Ce plan entraîne une interrogation des données de la table. Enfin, nous obtenons un rapport de l’interrogation pour vérifier la qualité des données. L’idée principale est d’utiliser un grand nombre de fonctions d’étape de validation pour révéler des incohérences ou des erreurs dans le tableau de données.\nLa deuxième méthodologie est utile dans un pipeline de transformation de données qui utilise des données tabulaires. Les fonctions de validation sont utilisées directement pour nous avertir des problèmes imprévus d’intégrité des données ou pour arrêter complètement le pipeline. L’arrêt est une bonne idée lorsque les processus dépendants et en aval (qui utiliseraient les données dans une certaine mesure) seraient compromis par de mauvaises données. Les deux méthodologies utilisent un ensemble commun de fonctions d’étape de validation, les «action levels» (c’est-à-dire les seuils d’échec) peuvent être définis par étapes. De plus, nous pouvons choisir d’utiliser nos propres fonctions R pour créer des effets secondaires comme la journalisation.\nLes deux workflows utilisent une large collection de fonctions d’étape de validation simples. Ces fonctions sont nommées de telle sorte que la fonction de validation soit évidente. Par exemple, la fonction col_vals_gt() teste si les valeurs de cellule dans une colonne sont supérieures à une valeur spécifiée. L’interface pour chaque fonction d’étape est cohérente mais également optimisée pour l’opération particulière.\nPrésentation pas à pas de pointblank dans le workflow de rapport sur la qualité des données Pour déterminer le niveau de qualité des données d’une table, nous utilisons ce que l’on appelle un agent. Il élabore un plan de validation, effectue l’interrogatoire et détient des informations sur cette interrogation (nous demanderions alors un rapport). La fonction create_agent() est utilisée pour créer l’agent. La table cible est donnée à l’agent et la table peut être un tibble ou un objet tbl_dbi créé via une connexion à la base de données et la fonction dplyr::tbl().\nNous utilisons des fonctions d’étape de validation pour construire un plan de validation. Il y en a 23 et certains vérifient l’existence ou le type de colonne (col_exists() ou le groupe de fonctions de la forme: col_is_*()) tandis que d’autres effectuent une vérification dans chaque cellule du tableau d’une colonne (par exemple, tous les col_vals_*() fonctions). Nous appliquons notre propre compréhension des données de la table cible lors de l’utilisation des fonctions d’étape de pointblank, et nous en utilisons autant que nécessaire pour des tests adéquats.\nAprès avoir utilisé les fonctions de l’étape de validation pour créer un plan de validation, la fonction interrogate() doit ensuite être utilisée. Avec cela, la table sera interrogée et les informations de validation nécessaires seront stockées dans l’agent.\nUtilisons l’objet small_table pour des exemples:\nsmall_table #\u0026gt; # A tibble: 13 x 8 #\u0026gt; date_time date a b c d e f #\u0026gt; \u0026lt;dttm\u0026gt; \u0026lt;date\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 2016-01-04 11:00:00 2016-01-04 2 1-bcd-345 3 3423. TRUE high #\u0026gt; 2 2016-01-04 00:32:00 2016-01-04 3 5-egh-163 8 10000. TRUE low #\u0026gt; 3 2016-01-05 13:32:00 2016-01-05 6 8-kdg-938 3 2343. TRUE high #\u0026gt; 4 2016-01-06 17:23:00 2016-01-06 2 5-jdo-903 NA 3892. FALSE mid #\u0026gt; 5 2016-01-09 12:36:00 2016-01-09 8 3-ldm-038 7 284. TRUE low #\u0026gt; 6 2016-01-11 06:15:00 2016-01-11 4 2-dhe-923 4 3291. TRUE mid #\u0026gt; 7 2016-01-15 18:46:00 2016-01-15 7 1-knw-093 3 843. TRUE high #\u0026gt; 8 2016-01-17 11:27:00 2016-01-17 4 5-boe-639 2 1036. FALSE low #\u0026gt; 9 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 10 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 11 2016-01-26 20:07:00 2016-01-26 4 2-dmx-010 7 834. TRUE low #\u0026gt; 12 2016-01-28 02:51:00 2016-01-28 2 7-dmx-010 8 108. FALSE low #\u0026gt; 13 2016-01-30 11:23:00 2016-01-30 1 3-dka-303 NA 2230. TRUE high  Le plan de validation de ce tableau utilise les assertions suivantes:\nla colonne date_time est une colonne date-heure la colonne f ne contient que les valeurs \"low\", \"mid\", and \"high\" les valeurs de la colonne a sont toutes inférieures à 10 Les valeurs de texte dans la colonne b sont conformes à un modèle spécifié la colonne d a des valeurs entre 0 et 5000 (pas entièrement vrai!)  Voici le code pour la validation:\nagent \u0026lt;- small_table %\u0026gt;% create_agent() %\u0026gt;% col_is_posix(vars(date_time)) %\u0026gt;% col_vals_in_set(vars(f), set = c(\u0026quot;low\u0026quot;, \u0026quot;mid\u0026quot;, \u0026quot;high\u0026quot;)) %\u0026gt;% col_vals_lt(vars(a), value = 10) %\u0026gt;% col_vals_regex(vars(b), regex = \u0026quot;^[0-9]-[a-z]{3}-[0-9]{3}$\u0026quot;) %\u0026gt;% col_vals_between(vars(d), left = 0, right = 5000) %\u0026gt;% interrogate() L’objet agent nous donne quelques informations sur la façon dont les choses se sont passées:\nagent #\u0026gt; pointblank agent // \u0026lt;agent_2020-01-13_04:14:09\u0026gt; #\u0026gt; #\u0026gt; number of validation steps: 5 #\u0026gt; #\u0026gt; interrogation (2020-01-13 04:14:09) resulted in: #\u0026gt; - 4 passing validations #\u0026gt; - 1 failing validation more info: `get_agent_report()` Les «4 passing validations» signifient que toutes les validations individuelles en quatre étapes de validation ont réussi sans erreur. Une étape de validation a échoué et au moins une unité de test a échoué (chaque cellule testée équivaut à 1 unité de test). Nous pouvons générer un rapport avec plus de détails en utilisant get_agent_report():\nget_agent_report(agent) Le rapport est une table gt, qui est imprimée par défaut si nous avons installé le paquet gt (utilisez remotes::install_github(\"rstudio/gt\") pour installer ce paquet). Les cinq premières colonnes du rapport sont reconnaissables car ce sont les noms des fonctions de l’étape de validation et leurs paramètres. Les preconditions colonne indique si la table a été modifiée juste avant l’interrogation (pour cette étape de validation). La colonne Units nous indique le nombre total d’unités de test pour chaque étape de validation. La colonne n_pass donne le nombre d’unités de test réussies tandis que la colonne f_pass indique la fraction d’unités de test réussies. Les indicateurs W, S, N nous indiquent si nous sommes entrés dans l’un des états WARN, STOP ou NOTIFY pour ces étapes de validation. Étant donné que nous n’avons défini aucun seuil pour ces États, ils ne sont pas pertinents pour ce rapport. Enfin, l’indicateur Extract nous indique si des extraits de données sont disponibles pour les unités de test ayant échoué. Pour l’étape 5, l’étape de validation col_vals_between(), un extrait de données est disponible. Nous pouvons jeter un œil à cet extrait avec get_data_extracts():\nget_data_extracts(agent, i = 5) #\u0026gt; # A tibble: 1 x 8 #\u0026gt; date_time date a b c d e f #\u0026gt; \u0026lt;dttm\u0026gt; \u0026lt;date\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 2016-01-04 00:32:00 2016-01-04 3 5-egh-163 8 10000. TRUE low Rappelons que l'étape 5 a affirmé que toutes les valeurs de la colonne d doivent être comprises entre 0 et 5000, cependant, cet extrait de small_table montre que la colonne d a une valeur qui se situe en dehors de cette plage spécifiée.\nProcédure pas à pas de pointblank dans le workflow de validation des données basé sur le pipeline La deuxième méthodologie, la validation des données par pipeline, simplifie quelque peu le processus de vérification directe des données. Aucun agent n’est impliqué ici et nous appelons plutôt les fonctions d’étape de validation directement sur les objets de la table de données. Parce qu’il n’y a pas d’agent, il n’y aura pas non plus de rapport. L’idée est que les effets secondaires sont les plus importants ici (les données passeront par les fonctions de validation inchangées). Nous pouvons déclencher des avertissements, générer des erreurs ou écrire des journaux en cas de dépassement des seuils d’échec spécifiés.\nOù ferions-nous cela? Lors de l’importation de données, nous pourrions tester ces données en les passant par quelques fonctions d’étape de validation avec des niveaux de seuil warn_at et stop_at définis. Si nous devions transformer un tableau de données, nous pourrions également utiliser un ensemble de fonctions d’étape de validation comme mesure d’AQ et de CQ. Si la mauvaise qualité des données peut être mauvaise pour un produit de données en aval, il est probablement préférable d’arrêter le processus par le biais de tests de validation pointblank, puis d’effectuer une analyse des causes profondes pour résoudre le problème de qualité des données.\nUtilisons les instructions de l’exemple précédent pour travailler dans le workflow de validation des données basé sur le pipeline. Dans ce cas, nous utiliserons un simple appel de la fonction action_levels() pour générer l’objet al. Il est passé à l’argument actions de chaque fonction d’étape de validation. Le paramètre implique que le pipeline sera arrêté en cas de défaillance d’une seule unité de test (avec stop_at = 1).\n# Create an `action_levels` object, stopping the pipeline # if we get a single failing test unit al \u0026lt;- action_levels(stop_at = 1) small_table %\u0026gt;% col_is_posix(vars(date_time), actions = al) %\u0026gt;% col_vals_in_set(vars(f), set = c(\u0026quot;low\u0026quot;, \u0026quot;mid\u0026quot;, \u0026quot;high\u0026quot;), actions = al) %\u0026gt;% col_vals_lt(vars(a), value = 10, actions = al) %\u0026gt;% col_vals_regex(vars(b), regex = \u0026quot;^[0-9]-[a-z]{3}-[0-9]{3}$\u0026quot;, actions = al) %\u0026gt;% col_vals_between(vars(d), left = 0, right = 5000, actions = al) Error: The validation (`col_vals_between()`) meets or exceeds the stop threshold C’est l’un de ces moments où nous pourrions être super heureux de voir une erreur. Le paramètre de seuil a arrêté l’évaluation du pipeline et, à son tour, arrête le script en cours d’exécution s’il est déployé et s’exécute automatiquement sur la version standard. La fonction action_levels() est assez puissante et elle nous permet de définir des fonctions personnalisées qui sont évaluées lors de la saisie de chacun des trois états de défaillance. Dans ce type de workflow, nous n’avons pas besoin de définir ces fonctions, pointblank nous aidera automatiquement à cela.\nEssayez pointblank! Ces courtes démonstrations présentent les principales caractéristiques des deux workflows de validation des données de pointblank. Il existe de nombreuses choses que vous pouvez faire pour définir précisément les étapes de validation et pour que l’action correcte se produise lors de la saisie de différents états de défaillance. J’espère que vous êtes enclin à l’essayer sur vos propres données!\n Die neueste Version des pointblank-Pakets erleichtert die Validierung Ihrer Daten mit Workflows, die auf Ihre Datenqualitätsanforderungen abgestimmt sind. Sie können pointblank 0.3 von CRAN installieren mit:\ninstall.packages(\u0026quot;pointblank\u0026quot;) Das Entwurfsziel von pointblank besteht darin, zwei wichtige Datenvalidierungs-Workflows mit einem gemeinsamen Satz von Validierungsschrittfunktionen zu ermöglichen. Der geschriebene Code sollte mit Daten in lokalen Datentabellen und mit Daten in Datenbanken gleichermaßen gut funktionieren.\nDie beiden wichtigsten Workflows, bei denen pointblank hilft, sind:\nBerichterstattung zur Datenqualität Pipeline-basierte Datenvalidierungen  Der erste Workflow befasst sich mit der Datenqualität der Zieltabelle. Man würde Validierungsschrittfunktionen verwenden, um einen Validierungsplan zu erstellen. Dieser Plan führt zu einer Abfrage der Tabellendaten. Schließlich erhalten wir einen Bericht über die Abfrage, um die Datenqualität festzustellen. Es wird empfohlen, eine große Anzahl von Validierungsschrittfunktionen zu verwenden. Mit mehr von ihnen können wir Inkonsistenzen oder Fehler in der Tabelle besser aufdecken.\nDer zweite Workflow ist in einer Datentransformationspipeline nützlich, die Tabellendaten verwendet. Die Validierungsfunktionen werden direkt verwendet, um uns entweder vor unvorhergesehenen Problemen mit der Datenintegrität zu warnen oder um die Pipeline vollständig zu stoppen. Anhalten ist eine gute Idee, wenn abhängige, nachgelagerte Prozesse (die die Daten in gewissem Umfang nutzen würden) durch schlechte Daten beeinträchtigt würden. Beide Workflows verwenden einen gemeinsamen Satz von Validierungsschrittfunktionen. “Action levels” (d. H. Fehlerschwellen) können schrittweise festgelegt werden. Zusätzlich können wir unsere eigenen R-Funktionen verwenden, um Nebenwirkungen wie das Schreiben von Protokolldateien zu erzeugen.\nBeide Workflows verwenden eine große Sammlung einfacher Validierungsschrittfunktionen. Diese Funktionen werden so benannt, dass es offensichtlich ist, was die Validierung bewirkt. Beispielsweise testet die Funktion col_vals_gt(), ob die Zellenwerte in einer Spalte größer als ein angegebener Wert sind. Die Schnittstelle für jede Schrittfunktion ist konsistent, aber auch für die jeweilige Operation optimiert.\nExemplarische Vorgehensweise von pointblank im Workflow für die Berichterstellung zur Datenqualität Um die Datenqualität für eine Tabelle zu bestimmen, verwenden wir einen Agenten. Es entwickelt einen Validierungsplan, führt die Befragung durch und enthält Informationen zu dieser Befragung (wir würden dann um einen Bericht bitten). Mit der Funktion create_agent() wird der Agent erstellt. Die Zieltabelle wird dem Agenten übergeben, und die Tabelle kann ein tibble- oder ein tbl_dbi-Objekt sein, das über eine Datenbankverbindung und die Funktion dplyr::tbl() erstellt wurde.\nWir verwenden Validierungsschrittfunktionen, um einen Validierungsplan zu erstellen. Es gibt 23 von ihnen und einige prüfen die Existenz oder den Typ der Spalte (col_exists() oder die Gruppe von col_is_*() -Funktionen), während andere eine Prüfung in jeder Tabellenzelle innerhalb einer Spalte durchführen (z. B. alle col_vals_*() Funktionen). Wir wenden bei der Verwendung der Pointblank-Step-Funktionen unser eigenes Verständnis der Daten in der Zieltabelle an und verwenden so viele, wie für angemessene Tests erforderlich sind.\nNachdem Sie Validierungsschrittfunktionen zum Erstellen eines Validierungsplans verwendet haben, sollte die Funktion interrogate() verwendet werden. Damit wird die Tabelle abgefragt und die notwendigen Validierungsinformationen im Agenten gespeichert.\nDas pointblank-Paket enthält einen Datensatz mit dem Namen small_table. Wir werden es für alle kommenden Beispiele verwenden:\nsmall_table #\u0026gt; # A tibble: 13 x 8 #\u0026gt; date_time date a b c d e f #\u0026gt; \u0026lt;dttm\u0026gt; \u0026lt;date\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 2016-01-04 11:00:00 2016-01-04 2 1-bcd-345 3 3423. TRUE high #\u0026gt; 2 2016-01-04 00:32:00 2016-01-04 3 5-egh-163 8 10000. TRUE low #\u0026gt; 3 2016-01-05 13:32:00 2016-01-05 6 8-kdg-938 3 2343. TRUE high #\u0026gt; 4 2016-01-06 17:23:00 2016-01-06 2 5-jdo-903 NA 3892. FALSE mid #\u0026gt; 5 2016-01-09 12:36:00 2016-01-09 8 3-ldm-038 7 284. TRUE low #\u0026gt; 6 2016-01-11 06:15:00 2016-01-11 4 2-dhe-923 4 3291. TRUE mid #\u0026gt; 7 2016-01-15 18:46:00 2016-01-15 7 1-knw-093 3 843. TRUE high #\u0026gt; 8 2016-01-17 11:27:00 2016-01-17 4 5-boe-639 2 1036. FALSE low #\u0026gt; 9 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 10 2016-01-20 04:30:00 2016-01-20 3 5-bce-642 9 838. FALSE high #\u0026gt; 11 2016-01-26 20:07:00 2016-01-26 4 2-dmx-010 7 834. TRUE low #\u0026gt; 12 2016-01-28 02:51:00 2016-01-28 2 7-dmx-010 8 108. FALSE low #\u0026gt; 13 2016-01-30 11:23:00 2016-01-30 1 3-dka-303 NA 2230. TRUE high  Der Validierungsplan für diese Tabelle verwendet die folgenden Zusicherungen:\nDie Spalte date_time ist eine Datum-Uhrzeit-Spalte Spalte f enthält nur die Werte \"low\", \"mid\" und \"high\" Die Werte in Spalte a sind alle kleiner als 10 Die Zeichenfolgen in Spalte b entsprechen einem angegebenen regulären Ausdruck Spalte d hat Werte im Bereich von 0 bis 5000 (dies ist nicht ganz richtig!)  Hier ist der Code für die obige Validierungslogik:\nagent \u0026lt;- small_table %\u0026gt;% create_agent() %\u0026gt;% col_is_posix(vars(date_time)) %\u0026gt;% col_vals_in_set(vars(f), set = c(\u0026quot;low\u0026quot;, \u0026quot;mid\u0026quot;, \u0026quot;high\u0026quot;)) %\u0026gt;% col_vals_lt(vars(a), value = 10) %\u0026gt;% col_vals_regex(vars(b), regex = \u0026quot;^[0-9]-[a-z]{3}-[0-9]{3}$\u0026quot;) %\u0026gt;% col_vals_between(vars(d), left = 0, right = 5000) %\u0026gt;% interrogate() Das Agent-Objekt gibt uns ein paar Informationen über die Befragung:\nagent #\u0026gt; pointblank agent // \u0026lt;agent_2020-01-13_04:14:09\u0026gt; #\u0026gt; #\u0026gt; number of validation steps: 5 #\u0026gt; #\u0026gt; interrogation (2020-01-13 04:14:09) resulted in: #\u0026gt; - 4 passing validations #\u0026gt; - 1 failing validation more info: `get_agent_report()` Die 4 passing validations bedeuten, dass alle Einzelvalidierungen in vier Validierungsschritten fehlerfrei bestanden wurden. Ein Validierungsschritt ist fehlgeschlagen, wobei mindestens eine Testeinheit ausgefallen ist (jede getestete Zelle entspricht 1 Testeinheit). Mit get_agent_report() können wir einen detaillierteren Bericht erstellen:\nget_agent_report(agent) Der Bericht ist eine gt-Tabelle, die standardmäßig gedruckt wird, wenn das gt-Paket installiert ist (verwenden Sie remotes::install_github(\"rstudio/gt\"), um dieses Paket zu installieren). Die ersten fünf Spalten des Berichts sind erkennbar, da sie Namen der Validierungsschrittfunktionen und ihrer Parameter sind. Die Spalte preconditions? gibt an, ob die Tabelle unmittelbar vor der Abfrage geändert wurde (für diesen Validierungsschritt). In der Spalte Units wird die Gesamtzahl der Testeinheiten für jeden Validierungsschritt angezeigt. Die Spalte n_pass gibt die Anzahl der bestandenen Testeinheiten an, während die Spalte f_pass den Anteil der bestandenen Testeinheiten angibt. Die W-, S- und N-Anzeigen zeigen an, ob wir für diese Überprüfungsschritte einen der Zustände WARN, STOP oder NOTIFY eingegeben haben. Da wir für diese Staaten keine Schwellenwerte festgelegt haben, sind sie für diesen Bericht nicht relevant. Schließlich gibt der Indikator Extract Auskunft darüber, ob für fehlerhafte Testeinheiten Datenextrakte verfügbar sind. Für step 5, den Validierungsschritt col_vals_between(), steht ein Datenextrakt zur Verfügung. Wir können uns diesen Auszug mit get_data_extracts() ansehen:\nget_data_extracts(agent, i = 5) #\u0026gt; # A tibble: 1 x 8 #\u0026gt; date_time date a b c d e f #\u0026gt; \u0026lt;dttm\u0026gt; \u0026lt;date\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 2016-01-04 00:32:00 2016-01-04 3 5-egh-163 8 10000. TRUE low Denken Sie daran, dass bei der Validierung in step 5 festgestellt wurde, dass alle Werte in Spalte d zwischen 0 und 5000 liegen sollten. Dieser Auszug aus small_table zeigt jedoch, dass Spalte d einen Wert hat, der außerhalb des angegebenen Bereichs liegt.\nEine exemplarische Vorgehensweise für pointblank im Pipeline-basierten Datenüberprüfungs-Workflow Der zweite Workflow, die pipelinebasierte Datenüberprüfung, vereinfacht die direkte Überprüfung der Daten ein wenig. Hier ist kein Agent beteiligt. Stattdessen rufen wir Validierungsschrittfunktionen direkt auf den Datentabellenobjekten auf. Da es keinen Agenten gibt, wird es auch keinen Bericht geben. Die Idee ist, dass die Nebenwirkungen hier am wichtigsten sind (die Daten durchlaufen die Validierungsfunktionen unverändert). Wir können Warnungen auslösen, Fehler auslösen oder Protokolle ausschreiben, wenn bestimmte Fehlerschwellen überschritten werden.\nWo würden wir das machen? Beim Importieren von Daten konnten wir diese Daten testen, indem wir einige Validierungsschrittfunktionen mit festgelegten Schwellenwerten für warn_at und stop_at durchliefen. Wenn wir eine Datentabelle transformieren würden, könnten wir ebenfalls eine Reihe von Validierungsschrittfunktionen als QA / QC-Maß verwenden. Wenn eine schlechte Datenqualität für ein nachgeschaltetes Datenprodukt schlecht sein könnte, ist es wahrscheinlich besser, den Prozess durch pointblank-Validierungstests zu stoppen und anschließend eine Ursachenanalyse durchzuführen, um das Datenqualitätsproblem zu beheben.\nVerwenden Sie die Anweisungen aus dem vorherigen Beispiel, um im Workflow für die pipelinebasierte Datenüberprüfung zu arbeiten. In diesem Fall verwenden wir einen einfachen Aufruf der action_levels() -Funktion, um das al-Objekt zu generieren. Es wird an das Argument actions jeder Validierungsschrittfunktion übergeben. Die Einstellung impliziert, dass die Pipeline gestoppt wird, wenn eine einzelne Testeinheit ausfällt (mit stop_at = 1).\n# Create an `action_levels` object, stopping the pipeline # if we get a single failing test unit al \u0026lt;- action_levels(stop_at = 1) small_table %\u0026gt;% col_is_posix(vars(date_time), actions = al) %\u0026gt;% col_vals_in_set(vars(f), set = c(\u0026quot;low\u0026quot;, \u0026quot;mid\u0026quot;, \u0026quot;high\u0026quot;), actions = al) %\u0026gt;% col_vals_lt(vars(a), value = 10, actions = al) %\u0026gt;% col_vals_regex(vars(b), regex = \u0026quot;^[0-9]-[a-z]{3}-[0-9]{3}$\u0026quot;, actions = al) %\u0026gt;% col_vals_between(vars(d), left = 0, right = 5000, actions = al) Error: The validation (`col_vals_between()`) meets or exceeds the stop threshold Dies ist eine der Situationen, in denen wir uns möglicherweise über einen Fehler freuen. Die Schwellenwerteinstellung hat die Auswertung der Pipeline gestoppt und stoppt das ausgeführte Skript, wenn es bereitgestellt wird und automatisch regelmäßig ausgeführt wird. Die action_levels()-Funktion ist sehr leistungsfähig und ermöglicht es uns, benutzerdefinierte Funktionen zu definieren, die beim Eingeben der drei Fehlerzustände ausgewertet werden. In dieser Art von Workflow müssen diese Funktionen nicht definiert werden. Pointblank erledigt automatisch die sinnvolle Aufgabe und gibt eine warning() oder eine stop()-Meldung aus.\nBitte testen Sie das pointblank-Paket Diese kurzen Demonstrationen zeigen die Hauptmerkmale der beiden Datenvalidierungs-Workflows von pointblank. Es gibt viele Möglichkeiten, um die Überprüfungsschritte genau zu definieren und die richtige Aktion auszulösen, wenn verschiedene Fehlerzustände eingegeben werden. Ich hoffe, Sie sind geneigt, es an Ihren eigenen Daten auszuprobieren!\n  function openLang(evt, cityName) { var i, tabcontent, tablinks; tabcontent = document.getElementsByClassName(\"tabcontent\"); for (i = 0; i ","date":1578873600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578894083,"objectID":"aa10b734f8d65608a1364dd6e4d12dd8","permalink":"/post/pointblank-0-3/","publishdate":"2020-01-13T00:00:00Z","relpermalink":"/post/pointblank-0-3/","section":"post","summary":"There is a new release of the **pointblank** package. It tries to prove that assessing data quality does *not* have to be difficult.","tags":["R Packages"],"title":"pointblank v0.3","type":"post"},{"authors":[],"categories":[],"content":"    English  French  German    The newest release of the blastula package lets you to do amazing things with HTML email in R and RStudio Connect. You can install blastula 0.3 from CRAN with:\ninstall.packages(\u0026quot;blastula\u0026quot;) This is a huge release! There are so many new and improved features we won’t be able to get through all of them here. Let’s focus on just two: R Markdown report emailing and improved HTML emailing using SMTP.\nR Markdown Report Emailing via RStudio Connect The capability to email a rendered R Markdown document in RStudio Connect has been available for well over a year. What would happen is that the report would be in the form of an attachment and message portion of the email would be prepared largely by RStudio Connect. With blastula v0.3, we can now create an email message body directly with R Markdown. Moreover, we can have a ‘main’ report for RStudio Connect viewers (with all of the details) and an ‘email’ version of the report that contains only the necessary elements for the purposes of email.\nStatic elements like ggplots and images can be part of the R Markdown email. The contents are faithfully converted to an HTML email message body that is fully responsive, so it’ll look great on both larger displays and on mobile devices. We went to great lengths to test and ensure that received emails display without problems on dozens of email clients.\nIf you thought that emailing R Markdown reports from RStudio Connect was a bit more difficult than should be, you’ll like this next part. There is now an easier-to-use methodology for associating an email to a published R Markdown report. The function prepare_rsc_example_files() is included to generate a set of example files relevant to R Markdown emailing in RStudio Connect. It provides a working example of a main .Rmd document, an email .Rmd document, and a CSV file that can be included as an attachment (any files generated from the main .Rmd document can also be attached). Documentation that explains how these documents interact, which blastula functions are used, and how to publish to RSC, is available in the internal documentation for the attach_connect_email() function. An updated support document in the official RStudio Connect documentation is forthcoming.\nI’m pretty sure that RStudio Connect users and the recipients of these emails will love the changes implemented here. Expect further improvements to R Markdown emailing via RStudio Connect in future releases of blastula.\nImproved HTML Emailing Using SMTP RStudio Connect isn’t the only way to send emails with blastula. We can opt to send our own custom emails through an SMTP server we have access to (e.g., Gmail, Outlook, etc.). These are HTML emails that are, again, responsive to display size and have been well tested on dozens of email clients. Let’s quickly look at three things that have changed for the better with regard to email composition and SMTP sending.\nRevised message composition with improved security Previously, text interpolation features from the glue package were built into the compose_email() function. This means we could have used the string \"The date and time of sending is {Sys.time()}.\" directly as input to, say, the message footer. Having the potential for R evaluation in strings invites security risks, so, this is no longer possible. Instead, we can simply opt to use glue::glue() ourselves or paste(). When there is any Markdown or HTML element, the md() function is required. Here is an example of a simple message that uses Markdown:\nemail \u0026lt;- compose_email( body = md( \u0026quot; ## Hello! This is an email message that was generated by the blastula package. Yep, we can use **Markdown** formatting but be sure to use the `md()` function. Here is a link to a great song ([E-MAIL ME!](https://youtu.be/-FcJbEg3vX8)). Cheers, The blastula team \u0026quot;), footer = md( \u0026quot; sent via the [blastula](https://rich-iannone.github.io/blastula) R package \u0026quot;) )  We can always preview the email object in the RStudio Viewer while getting the composition just right. For more details on email message composition with compose_email(), have a look at the Simple Email Composition article on the project website.\nNo external software to install for SMTP sending In the few years that blastula has been available, it relied on various pieces of external software for sending email. Not anymore. This release favors the creation of an RFC-2822 email body, sending through the excellent curl package. This all means that emails can now be sent dependably with the smtp_send() function on all the major platforms with no up-front installation of a third-party binary.\nImproved credentials handling The package now ships with functions for setting up and retrieving SMTP configuration and credentials information. We can set this in the system-wide key-value store with create_smtp_creds_key(). With such a key added, the credentials helper creds_key() can be used when sending email through smtp_send(). Alternatively, a credentials file can be created using the create_smtp_creds_file() function (retrieved with the creds_file() credentials helper). Lastly, credentials can be fully specified at the time of sending with the creds() function. Whenever a password is needed for setup, a prompt will appear for password entry and the password text will be obscured.\nMore! Other quality-of-life improvements include automatic image embedding (via Base64 encoding) from the use of the add_image() and add_ggplot() functions when used in conjunction with compose_email(). There’s the option for automatic image deployment and retrieval of the external image tag through the add_imgur_image() function. Finally, there is a new set of block_*() functions that help us compose emails with more complex layouts.\nWrapping Up I hope that you try out the new release of the blastula package. So many useful things can be created with R and having the means to deliver our findings through email is super satisfying both for the sender and the recipient.\n La nouvelle version du package blastula vous permet de faire des choses sympas avec les e-mails HTML dans R et RStudio Connect. Installez blastula 0.3 de CRAN avec:\ninstall.packages(\u0026quot;blastula\u0026quot;) C’est une énorme sortie et donc il y a beaucoup de nouvelles choses… Je ne pense pas qu’il y ait assez de temps pour parler de tout ici. Mais ça va, regardons deux choses: envoyer des rapports par e-mail avec R Markdown et des e-mails HTML améliorés (via un serveur SMTP).\nEmailing R Markdown Rapports avec RStudio Connect La possibilité d’envoyer un document R Markdown rendu par e-mail est disponible depuis longtemps (dans RStudio Connect). Mais c’était en pièce jointe (un peu décevant). Avec le nouveau package blastula, nous pouvons désormais créer un e-mail entièrement avec R Markdown (le contenu va directement dans l’e-mail). De plus, nous pouvons avoir un rapport «principal» pour les téléspectateurs RStudio Connect (avec tous les détails) et une version «e-mail» du rapport qui contient uniquement les éléments nécessaires aux fins de l’e-mail. Ah… beaucoup mieux!\nLes éléments statiques tels que ggplots et les images peuvent faire partie de l’e-mail R Markdown. Le contenu est converti en un corps de message électronique HTML qui a fière allure sur les grands écrans et sur les téléphones cellulaires. Nous avons fait de grands efforts pour tester tout cela. Cela impliquait de consulter les e-mails de nombreux clients de messagerie.\nL’envoi de rapports R Markdown par RStudio Connect a été un peu difficile. Il est désormais plus facile d’associer un e-mail à un rapport R Markdown publié. La fonction prepare_rsc_example_files() peut être utilisée pour générer un ensemble d’exemples de fichiers. Ces fichiers montrent comment effectuer des e-mails R Markdown dans RStudio Connect. Les fichiers incluent un document .Rmd principal, un document .Rmd de courrier électronique et un fichier CSV qui peut être inclus en tant que pièce jointe. Pourquoi le CSV? Parce que tous les fichiers générés à partir du document principal .Rmd peuvent également être joints! La documentation qui explique comment ces documents interagissent, quelles fonctions blastula sont utilisées et comment publier sur RSC, est disponible dans la documentation interne de la fonction attach_connect_email().\nOuais. Je suis certain que les utilisateurs de RStudio Connect et les destinataires de ces e-mails adoreront les changements mis en œuvre ici. Nous apporterons plus de modifications aux e-mails R Markdown via RStudio Connect dans les prochaines versions de blastula.\nEmailing HTML amélioré à l’aide de SMTP RStudio Connect n’est pas le seul moyen d’envoyer des e-mails avec blastula. Nous pouvons envoyer des e-mails via un serveur SMTP auquel nous avons accès (par exemple, Gmail, Outlook, etc.). Voyons rapidement trois choses qui se sont améliorées en ce qui concerne la composition des e-mails et l’envoi SMTP.\nComposition des messages révisée avec plus de sécurité Auparavant, les fonctions d’interpolation de texte du package glue étaient intégrées à la fonction compose_email(). Cela signifie que nous aurions pu utiliser la déclaration \"The date and time of sending is {Sys.time()}.\" Directement comme entrée dans, disons, le pied de page du message. Le fait d’avoir le potentiel d’évaluation R dans les chaînes entraîne des risques de sécurité, ce n’est donc plus possible. Au lieu de cela, nous pouvons simplement choisir d’utiliser glue::glue() nous-mêmes ou paste(). Lorsqu’il y a un élément Markdown ou HTML, la fonction md() est requise. Voici un exemple de message simple qui utilise Markdown (c’est en anglais):\nemail \u0026lt;- compose_email( body = md( \u0026quot; ## Hello! This is an email message that was generated by the blastula package. Yep, we can use **Markdown** formatting but be sure to use the `md()` function. Here is a link to a great song ([E-MAIL ME!](https://youtu.be/-FcJbEg3vX8)). Cheers, The blastula team \u0026quot;), footer = md( \u0026quot; sent via the [blastula](https://rich-iannone.github.io/blastula) R package \u0026quot;) )  Nous pouvons toujours prévisualiser l’objet email dans la RStudio Viewer tout en obtenant la composition parfaite. Pour plus de détails sur la composition des e-mails avec compose_email(), consultez l’article Simple Email Composition sur le site web du projet.\nAucun logiciel externe n’est nécessaire pour envoyer des e-mails avec SMTP Au cours des quelques années où blastula a été disponible, il s’est appuyé sur divers logiciels externes pour envoyer des e-mails. Ce n’est plus vrai. Nous créons maintenant un corps d’e-mail RFC-2822 et envoyons des e-mails avec une fonction du package curl. Désormais, les e-mails peuvent désormais être envoyés de manière fiable avec la fonction smtp_send() sur toutes les principales plates-formes informatiques sans aucune dépendance difficile à installer.\nAmélioration de la gestion des informations d’identification Le package possède désormais des fonctions de configuration et de récupération des informations de configuration et d’informations d’identification SMTP. Nous pouvons configurer cela avec create_smtp_creds_key(). Avec une telle clé ajoutée, l’aide aux informations d’identification creds_key() peut être utilisée lors de l’envoi d’e-mails via smtp_send(). Alternativement, un fichier d’informations d’identification peut être créé en utilisant la fonction create_smtp_creds_file() (récupérée avec creds_file()). Enfin, les informations d’identification peuvent être entièrement spécifiées au moment de l’envoi avec la fonction creds(). Chaque fois qu’un mot de passe est nécessaire, une invite apparaîtra pour la saisie du mot de passe (le texte du mot de passe sera masqué).\nIl y a encore plus! D’autres changements incluent l’intégration automatique d’images (via l’encodage Base64) à partir de l’utilisation des fonctions add_image() et add_ggplot() lorsqu’elles sont utilisées avec compose_email(). La fonction add_imgur_image() facilite l’utilisation d’images externes dans les e-mails. Enfin, il existe un nouvel ensemble de fonctions block_*() qui nous aident à composer des e-mails avec des mises en page plus complexes.\nConclusion J’espère que vous essayez la nouvelle version du package blastula. Nous pouvons créer des choses utiles avec R et avoir les moyens de livrer nos résultats par e-mail est super cool pour l’expéditeur et le destinataire.\n Mit der neuen Version des blastula-Pakets können Sie in R und RStudio Connect coole Dinge mit HTML-E-Mails tun. Installieren Sie CRAN blastula 0.3 mit:\ninstall.packages(\u0026quot;blastula\u0026quot;) Dies ist ein ziemlich umfangreiches Software-Upgrade! Es gibt so viele neue und verbesserte Funktionen, dass wir sie hier nicht alle durcharbeiten können. Schauen wir uns zwei neue Themen an: R Markdown Bericht-E-Mail und verbessertes HTML-E-Mail mit SMTP.\nR Markdown E-Mail-Berichte mit RStudio Connect Die Möglichkeit, ein per E-Mail gesendetes R Markdown-Dokument zu senden, ist seit langem verfügbar (in RStudio Connect). Aber es war anhaftend (etwas enttäuschend). Mit dem neuen Blastula-Paket können wir jetzt eine E-Mail komplett mit R Markdown erstellen (der Inhalt geht direkt in die E-Mail). Außerdem können wir einen “Haupt”-Report für die Zuschauer RStudio Connect (mit allen Details) und eine “E-Mail”-Version des Berichts haben, die nur die für die Zwecke der E-Mail erforderlichen Elemente enthält. Viel besser!\nStatische Elemente wie ggplots und Bilder können Teil der R Markdown-E-Mail sein. Der Inhalt wird in einen HTML-Nachrichtentext konvertiert, der auf große Desktop-Displays und Handys großartig aussieht. Wir haben große Anstrengungen unternommen, um all dies zu testen. Dies beinhaltete das Betrachten der E-Mails vieler E-Mail-Clients.\nEs war ein bisschen schwierig, R Markdown von RStudio Connect zu melden. Es ist jetzt einfacher, eine E-Mail mit einem veröffentlichten R Markdown-Report zu verknüpfen. Die Funktion prepare_rsc_example_files() kann verwendet werden, um einen Satz von Beispieldateien zu generieren. Diese Dateien zeigen, wie R Markdown-E-Mails in RStudio Connect erstellt werden. Die Dateien enthalten ein Haupt-RMD-Dokument, ein RMD-E-Mail-Dokument und eine CSV-Datei, die als Anhang beigefügt werden kann. Warum die CSV? Denn alle Dateien, die aus dem Hauptdokument .Rmd generiert wurden, können auch angehängt werden! Die Dokumentation, die erklärt, wie diese Dokumente interagieren, welche blastula-Funktionen verwendet werden und wie sie in RSC veröffentlicht werden, finden Sie in der internen Dokumentation der Funktion attach_connect_email().\nJa. Ich bin sicher, dass RStudio Connect-Nutzer und -Empfänger dieser E-Mails die hier vorgenommenen Änderungen lieben werden. In zukünftigen Versionen von blastula werden wir weitere Änderungen an R Markdown-E-Mails über RStudio Connect vornehmen.\nErweitertes HTML-E-Mailing über SMTP RStudio Connect ist nicht die einzige Möglichkeit, E-Mails mit blastula zu versenden. Wir können E-Mails über einen SMTP-Server senden, auf den wir Zugriff haben (z. B. Google Mail, Outlook usw.). Schauen wir uns kurz drei Dinge an, die sich in Bezug auf die E-Mail-Zusammensetzung und den SMTP-Versand verbessert haben.\nÜberarbeitete Nachrichtenkomposition mit mehr Sicherheit Zuvor waren die Textinterpolationsfunktionen des glue-Pakets in die Funktion compose_email() integriert. Dies bedeutet, dass wir die Anweisung \"The date and time of sending is {Sys.time()}.\" Direkt als Eintrag beispielsweise in der Fußzeile der Nachricht verwendet haben könnten. Das Potential zur Bewertung R in den Ketten zu haben, führt zu Sicherheitsrisiken, so dass dies nicht mehr möglich ist. Stattdessen können wir uns einfach dafür entscheiden, glue::glue() oder paste() zu verwenden. Wenn ein Markdown- oder HTML-Element vorhanden ist, ist die Funktion md() erforderlich. Hier ist ein Beispiel für eine einfache Nachricht, die Markdown verwendet:\nemail \u0026lt;- compose_email( body = md( \u0026quot; ## Hello! This is an email message that was generated by the blastula package. Yep, we can use **Markdown** formatting but be sure to use the `md()` function. Here is a link to a great song ([E-MAIL ME!](https://youtu.be/-FcJbEg3vX8)). Cheers, The blastula team \u0026quot;), footer = md( \u0026quot; sent via the [blastula](https://rich-iannone.github.io/blastula) R package \u0026quot;) )  Wir können weiterhin eine Vorschau des E-Mail-Objekts im RStudio Viewer anzeigen, um die perfekte Komposition zu erhalten. Weitere Informationen zum Verfassen von E-Mails mit compose_email() finden Sie im Artikel Simple Email Composition auf der Projektwebsite.\nZum Versenden von E-Mails mit SMTP ist keine externe Software erforderlich In den wenigen Jahren, in denen blastula verfügbar war, stützte er sich zum Versenden von E-Mails auf verschiedene externe Software. Das stimmt nicht mehr. Wir erstellen jetzt einen RFC-2822-E-Mail-Body und senden E-Mails mit einer curl-Paketfunktion. Jetzt können E-Mails mit der Funktion smtp_send() zuverlässig auf allen wichtigen Computerplattformen ohne schwer zu installierende Abhängigkeiten gesendet werden.\nVerbesserte Berechtigungsnachweisverwaltung Das Paket verfügt jetzt über Funktionen zum Konfigurieren und Abrufen von Konfigurationsinformationen und SMTP-Anmeldeinformationen. Wir können dies mit create_smtp_creds_key() konfigurieren. Mit einem solchen hinzugefügten Schlüssel kann die creds_key()-Hilfe zum Versenden von E-Mails über smtp_send() verwendet werden. Alternativ kann eine Berechtigungsnachweisdatei mit der Funktion create_smtp_creds_file() erstellt werden (abgerufen mit creds_file()). Schließlich können die Anmeldeinformationen zum Zeitpunkt des Sendens mit der Funktion creds() vollständig angegeben werden. Immer wenn ein Passwort erforderlich ist, erscheint eine Aufforderung zur Eingabe des Passworts (der Passworttext wird ausgeblendet).\nEs gibt noch mehr! Andere Änderungen umfassen die automatische Bildintegration (über Base64-Codierung) durch die Verwendung der Funktionen add_image() und add_ggplot(), wenn sie mit compose_email() verwendet werden. Die Funktion add_imgur_image() erleichtert die Verwendung externer Bilder in E-Mails. Schließlich gibt es eine neue Reihe von block_*()-Funktionen, mit denen wir E-Mails mit komplexeren Layouts erstellen können.\nDie Zukunft ist da Ich hoffe aufrichtig, dass Sie die neue Version des blastula-Pakets testen. Mit R können wir so viele nützliche Dinge erschaffen. Die Möglichkeit, unsere Ergebnisse per E-Mail zu übermitteln, ist für den Absender und den Empfänger eine absolute Freude.\n  function openLang(evt, cityName) { var i, tabcontent, tablinks; tabcontent = document.getElementsByClassName(\"tabcontent\"); for (i = 0; i ","date":1574380800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574454660,"objectID":"4d81e889cbfec92d782654b9d919f230","permalink":"/post/blastula-0-3/","publishdate":"2019-11-22T00:00:00Z","relpermalink":"/post/blastula-0-3/","section":"post","summary":"The newest release of the **blastula** package lets you to do amazing things with HTML email in **R** and **RStudio Connect**.","tags":["R Packages"],"title":"blastula v0.3","type":"post"},{"authors":null,"categories":null,"content":" The book entitled Exploring Data with R teaches you how to do data analysis with R. The book doesn’t assume any prior experience with programming making it a great introduction with easy-to-follow examples and useful exercises.\n","date":1571529600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571529600,"objectID":"20281aed3cfbf9fa7fca750da29de323","permalink":"/projects/exploring-data-with-r-book/","publishdate":"2019-10-20T00:00:00Z","relpermalink":"/projects/exploring-data-with-r-book/","section":"projects","summary":"An introductory book for data analysis in R.","tags":["R Books"],"title":"[R book] Exploring Data with R","type":"projects"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":[],"categories":null,"content":"","date":1547683200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547683200,"objectID":"ea57c95009d46583f549e9ae1d8a340d","permalink":"/talk/rstudio-conf-2019/","publishdate":"2019-01-17T00:00:00Z","relpermalink":"/talk/rstudio-conf-2019/","section":"talk","summary":"A talk given at rstudio::conf 2019.","tags":[],"title":"Introducing the gt Package","type":"talk"},{"authors":null,"categories":null,"content":" With the gt package, anyone can make wonderful-looking tables using the R programming language. The gt philosophy: we can construct a wide variety of useful tables with a cohesive set of table parts. These include the table header, the stub, the stub head, the column labels, the table body, and the table footer.\nThe gt API is designed to be both straightforward yet powerful. The emphasis is on simple functions for the everyday display table needs. However, there are functions for customizing and annotating tables to convey additional information.\n","date":1521504000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1521504000,"objectID":"31b25af6531d4d0883a784f3dab5370a","permalink":"/projects/gt-pkg/","publishdate":"2018-03-20T00:00:00Z","relpermalink":"/projects/gt-pkg/","section":"projects","summary":"Easily generate information-rich, publication-quality tables from R","tags":["R Packages"],"title":"[R package] gt","type":"projects"},{"authors":null,"categories":null,"content":" The blastula package makes it easy to produce and send HTML email from R. The message can have three content areas (the body, the header, and the footer) and we can insert Markdown text, R expressions, block-based components, and even some raw HTML. The underlying HTML/CSS is meant to display properly across a wide range of email clients and webmail services. The resulting email message is responsive so it’ll look great on computers and mobile devices.\n","date":1502582400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502582400,"objectID":"37022a39ee9e857e037bbd8ad639a07d","permalink":"/projects/blastula-pkg/","publishdate":"2017-08-13T00:00:00Z","relpermalink":"/projects/blastula-pkg/","section":"projects","summary":"The blastula R package lets us send HTML email messages.","tags":["R Packages"],"title":"[R package] blastula","type":"projects"},{"authors":null,"categories":null,"content":" The pointblank package let’s us validate data in local data frames or tibbles, in CSV and TSV files, and in database tables (PostgreSQL and MySQL). We can get a detailed summary report of the interrogation, showing how many individual tests in each validation step had passed or failed. The self-contained HTML report provides detailed information on the validation outcomes and it can be used as web content.\n","date":1487808000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487808000,"objectID":"0c925a48661aa287e516b3344a71ecb8","permalink":"/projects/pointblank-pkg/","publishdate":"2017-02-23T00:00:00Z","relpermalink":"/projects/pointblank-pkg/","section":"projects","summary":"The pointblank R package lets us validate data tables.","tags":["R Packages"],"title":"[R package] pointblank","type":"projects"},{"authors":null,"categories":null,"content":" The DiagrammeR package has a collection of graph functions allow you to create graph objects, modify those graphs, get information from the graphs, and do many other useful things. We can easily generate network graphs with data available in tabular datasets. Two specialized data frames contain node data and attributes (node data frames) and edges with associated edge attributes (edge data frames). Because the attributes are always kept alongside the node and edge definitions (within the graph object itself), we can easily work with them.\n","date":1419724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1419724800,"objectID":"672d8104f5a9af8960efacc7c5dceeab","permalink":"/projects/diagrammer-pkg/","publishdate":"2014-12-28T00:00:00Z","relpermalink":"/projects/diagrammer-pkg/","section":"projects","summary":"The DiagrammeR R package lets create, modify, and visualize network graphs.","tags":["R Packages"],"title":"[R package] DiagrammeR","type":"projects"},{"authors":null,"categories":null,"content":" The stationaRy package allows for fast retrieval of meteorological data from met stations located all over the world. Weather data originates from the 29,729 stations available in this dataset where many of these contain data that go back decades. The data comes from the Integrated Surface Dataset (ISD), which is maintained by the National Oceanic and Atmospheric Administration (NOAA).\n","date":1397347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1397347200,"objectID":"ef1413ba0f65aca93e7de598e310527b","permalink":"/projects/stationary-pkg/","publishdate":"2014-04-13T00:00:00Z","relpermalink":"/projects/stationary-pkg/","section":"projects","summary":"The stationaRy R package gives us access to historical weather data.","tags":["R Packages"],"title":"[R package] stationaRy","type":"projects"},{"authors":null,"categories":null,"content":" splitr is an R package for conducting trajectory and dispersion modeling with HYSPLIT. This is useful for atmospheric scientists as the package helps to determine, from one or more receptor sites, where arriving air masses originated. Conversely, it’s possible to model trajectories of air masses from receptor sites. Forward and backward modeling of gas-phase or particulate matter can also be conducted from defined sites. It’s a means to help explain how, where, and when chemicals and materials are atmospherically transported, dispersed, and deposited.\n","date":1386633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1386633600,"objectID":"89abb0b75e9bc0996c37fc60dd5c46f9","permalink":"/projects/splitr-pkg/","publishdate":"2013-12-10T00:00:00Z","relpermalink":"/projects/splitr-pkg/","section":"projects","summary":"The splitr R package helps model wind trajectories and particle dispersion.","tags":["R Packages"],"title":"[R package] splitr","type":"projects"}]